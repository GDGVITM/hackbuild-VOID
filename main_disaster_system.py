"""
Enhanced Real-Time Disaster Alert System v2.3
Advanced monitoring with comprehensive HTML visualizations and enhanced database storage
Now includes interactive dashboards, detailed reports, and enhanced map visualizations
"""

import os
import json
import time
import threading
import queue
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import json

# Core libraries
from dotenv import load_dotenv
import requests
import pandas as pd
import sqlite3

# Social Media APIs
import tweepy
import praw

# Notification services
from twilio.rest import Client
import pywhatkit as kit

# AI and NLP
import google.generativeai as genai
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  TextBlob not available - sentiment analysis will be skipped")
    TEXTBLOB_AVAILABLE = False

# Geographic services
from geopy.geocoders import Nominatim
import geocoder

# Load environment variables
load_dotenv()

@dataclass
class DisasterAlert:
    """Enhanced disaster alert data structure"""
    id: str
    disaster_type: str
    location: str
    latitude: Optional[float]
    longitude: Optional[float]
    confidence_score: float
    timestamp: datetime
    source_platform: str
    content: str
    author: str
    hashtags: List[str]
    severity_level: str  # low, medium, high, critical
    affected_radius_km: float

class RealTimeTwitterMonitor:
    """Real-time Twitter monitoring using Twitter API v2"""
    
    def __init__(self):
        """Initialize Twitter API v2 client"""
        # Load Twitter API credentials
        self.bearer_token = os.getenv('TWITTER_BEARER_TOKEN')
        self.api_key = os.getenv('TWITTER_API_KEY')
        self.api_secret = os.getenv('TWITTER_API_SECRET')
        self.access_token = os.getenv('TWITTER_ACCESS_TOKEN')
        self.access_token_secret = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')
        
        self.api_active = False
        self.twitter_client = None
        
        # Initialize Twitter API v2 client
        if self.bearer_token:
            try:
                import tweepy
                self.twitter_client = tweepy.Client(
                    bearer_token=self.bearer_token,
                    consumer_key=self.api_key,
                    consumer_secret=self.api_secret,
                    access_token=self.access_token,
                    access_token_secret=self.access_token_secret,
                    wait_on_rate_limit=True
                )
                
                # Test the connection
                try:
                    self.twitter_client.get_me()
                    self.api_active = True
                    print("‚úÖ Twitter API v2 initialized successfully")
                except Exception as test_error:
                    # Try with just bearer token for read-only access
                    self.twitter_client = tweepy.Client(bearer_token=self.bearer_token, wait_on_rate_limit=True)
                    try:
                        # Test with a simple search
                        test_tweets = self.twitter_client.search_recent_tweets("disaster", max_results=10)
                        self.api_active = True
                        print("‚úÖ Twitter API v2 (read-only) initialized successfully")
                    except Exception as e:
                        print(f"‚ùå Twitter API test failed: {e}")
                        self.api_active = False
                        
            except ImportError:
                print("‚ùå tweepy not installed. Install with: pip install tweepy")
                self.api_active = False
            except Exception as e:
                print(f"‚ùå Twitter API initialization failed: {e}")
                self.api_active = False
        else:
            print("‚ùå TWITTER_BEARER_TOKEN not found in .env file")
            print("üìù To enable real Twitter data fetching, add your Twitter API v2 credentials:")
            print("   1. Go to https://developer.twitter.com/en/portal/dashboard")
            print("   2. Create a new app or use existing one")
            print("   3. Copy the Bearer Token from your app's Keys tab")
            print("   4. Add to .env file: TWITTER_BEARER_TOKEN=your_bearer_token_here")
            print("   5. Restart the application")
            print("üîÑ System will use enhanced fallback data until API is configured")
            self.api_active = False
        
        self.disaster_keywords = [
            "earthquake", "tsunami", "flood", "wildfire", "hurricane",
            "tornado", "cyclone", "landslide", "drought", "volcano", 
            "blizzard", "storm", "disaster", "emergency", "evacuation",
            "rescue", "breaking", "alert", "warning", "crisis"
        ]

    def fetch_disaster_tweets(self, days_back: int = 7) -> List[Dict]:
        """Enhanced real-time disaster tweets with robust error handling and retry logic"""
        if not self.api_active:
            print("‚ùå Twitter API not available. Check your credentials in .env file")
            print("üìù Required: TWITTER_BEARER_TOKEN")
            return self.get_fallback_disaster_data()

        # Enhanced retry logic with multiple strategies
        max_retries = 3
        retry_delays = [5, 15, 30]  # Exponential backoff
        
        for attempt in range(max_retries):
            try:
                print(f"üê¶ Fetching real-time tweets about disasters... (Attempt {attempt + 1}/{max_retries})")
                
                # Multiple search strategies for better results
                search_strategies = [
                    # Strategy 1: Primary disaster keywords
                    {
                        'terms': ["earthquake", "flood", "fire", "storm"],
                        'locations': ["Mumbai", "Delhi", "India"],
                        'name': 'Primary Disasters'
                    },
                    # Strategy 2: Emergency terms
                    {
                        'terms': ["emergency", "disaster", "breaking", "alert"],
                        'locations': ["Tokyo", "California", "USA"],
                        'name': 'Emergency Alerts'
                    },
                    # Strategy 3: Specific disaster types
                    {
                        'terms': ["hurricane", "tornado", "tsunami", "cyclone"],
                        'locations': ["Japan", "Philippines", "Bangladesh"],
                        'name': 'Severe Weather'
                    }
                ]
                
                all_tweets = []
                
                for strategy in search_strategies:
                    try:
                        # Create focused query for each strategy
                        query = f"({' OR '.join(strategy['terms'])}) ({' OR '.join(strategy['locations'])}) -is:retweet lang:en"
                        
                        print(f"üìù {strategy['name']} Search: {query}")
                        print(f"üîç Looking for tweets from last {days_back} days...")
                        
                        # Search with smaller max_results to avoid rate limits
                        tweets = self.twitter_client.search_recent_tweets(
                            query=query,
                            max_results=30,  # Reduced to avoid rate limits
                            tweet_fields=['created_at', 'author_id', 'context_annotations', 'geo', 'lang', 'public_metrics'],
                            user_fields=['name', 'username', 'location', 'verified'],
                            expansions=['author_id']
                        )
                        
                        if tweets.data:
                            all_tweets.extend(tweets.data)
                            print(f"‚úÖ Found {len(tweets.data)} tweets for {strategy['name']}")
                        else:
                            print(f"‚ö†Ô∏è No tweets found for {strategy['name']}")
                            
                        # Rate limit protection - wait between strategies
                        import time
                        time.sleep(2)
                        
                    except Exception as strategy_error:
                        print(f"‚ö†Ô∏è Strategy '{strategy['name']}' failed: {strategy_error}")
                        continue
                
                if not all_tweets:
                    print("‚ö†Ô∏è No tweets found with any strategy")
                    if attempt < max_retries - 1:
                        wait_time = retry_delays[attempt]
                        print(f"‚è≥ Waiting {wait_time} seconds before retry...")
                        time.sleep(wait_time)
                        continue
                    else:
                        return self.get_fallback_disaster_data()
                
                # Remove duplicates
                unique_tweets = {}
                for tweet in all_tweets:
                    unique_tweets[tweet.id] = tweet
                
                final_tweets = list(unique_tweets.values())
                print(f"‚úÖ Found {len(final_tweets)} unique tweets total")
                
                # Process tweets into standard format - need to rebuild user mapping from all searches
                processed_tweets = []
                
                # Get all unique user IDs
                user_ids = list(set([tweet.author_id for tweet in final_tweets]))
                
                # Fetch user information in batch (if available)
                users_dict = {}
                try:
                    if user_ids and len(user_ids) <= 100:  # Twitter API limit
                        users_response = self.twitter_client.get_users(ids=user_ids, user_fields=['username', 'name', 'location', 'verified'])
                        if users_response.data:
                            users_dict = {user.id: user for user in users_response.data}
                            print(f"üìã Retrieved user info for {len(users_dict)} users")
                except Exception as user_error:
                    print(f"‚ö†Ô∏è Could not fetch user details: {user_error}")
                
                for tweet in final_tweets:
                    try:
                        user = users_dict.get(tweet.author_id)
                        location = self.extract_location(tweet, user)
                        
                        processed_tweet = {
                            'id': str(tweet.id),
                            'text': tweet.text,
                            'content': tweet.text,  # For compatibility
                            'author': user.username if user else f"user_{tweet.author_id}",
                            'author_name': user.name if user else 'Unknown User',
                            'created_at': tweet.created_at.isoformat() if tweet.created_at else datetime.now().isoformat(),
                            'location': location,
                            'retweet_count': tweet.public_metrics.get('retweet_count', 0) if hasattr(tweet, 'public_metrics') and tweet.public_metrics else 0,
                            'like_count': tweet.public_metrics.get('like_count', 0) if hasattr(tweet, 'public_metrics') and tweet.public_metrics else 0,
                            'reply_count': tweet.public_metrics.get('reply_count', 0) if hasattr(tweet, 'public_metrics') and tweet.public_metrics else 0,
                            'quote_count': tweet.public_metrics.get('quote_count', 0) if hasattr(tweet, 'public_metrics') and tweet.public_metrics else 0,
                            'hashtags': self.extract_hashtags_from_text(tweet.text),
                            'platform': 'twitter_api_v2_enhanced',
                            'verified': user.verified if user and hasattr(user, 'verified') else False,
                            'disaster_score': self.calculate_disaster_relevance_score(tweet.text)
                        }
                        
                        # Enhanced disaster filtering with scoring
                        if self.is_disaster_related(tweet.text) or processed_tweet['disaster_score'] > 0.5:
                            processed_tweets.append(processed_tweet)
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error processing tweet {tweet.id}: {e}")
                        continue
                
                # Sort by disaster relevance and recency
                processed_tweets.sort(key=lambda x: (x['disaster_score'], x['retweet_count'] + x['like_count']), reverse=True)
                
                print(f"üéØ Processed {len(processed_tweets)} disaster-related tweets from {len(final_tweets)} total")
                print(f"üìä Success! Retrieved real tweets from Twitter API")
                
                # Show top disaster tweets
                if processed_tweets:
                    print(f"\nüèÜ TOP DISASTER TWEETS:")
                    for i, tweet in enumerate(processed_tweets[:3], 1):
                        print(f"   {i}. @{tweet['author']}: {tweet['text'][:80]}...")
                        print(f"      üìä Score: {tweet['disaster_score']:.2f} | üîÑ {tweet['retweet_count']} RTs | ‚ù§Ô∏è {tweet['like_count']} likes")
                
                return processed_tweets
                
            except Exception as e:
                error_str = str(e).lower()
                print(f"‚ùå Error fetching real-time tweets (Attempt {attempt + 1}): {e}")
                
                # Enhanced error handling
                if "503" in error_str or "service unavailable" in error_str:
                    print("üö´ Twitter API temporarily unavailable (503 Service Unavailable)")
                    if attempt < max_retries - 1:
                        wait_time = retry_delays[attempt]
                        print(f"‚è≥ Waiting {wait_time} seconds before retry...")
                        time.sleep(wait_time)
                        continue
                elif "429" in error_str or "rate limit" in error_str:
                    print("‚è∞ Rate limited - API quota exceeded")
                    if attempt < max_retries - 1:
                        wait_time = 60  # Wait longer for rate limits
                        print(f"‚è≥ Waiting {wait_time} seconds for rate limit reset...")
                        time.sleep(wait_time)
                        continue
                elif "unauthorized" in error_str or "401" in error_str:
                    print("üîê Authentication failed - Check your Twitter API credentials")
                    break  # Don't retry auth errors
                elif "forbidden" in error_str or "403" in error_str:
                    print("üö´ Access forbidden - Your API access level may be insufficient")
                    break
                else:
                    print(f"üîç Generic API error: {e}")
                
                # If this is the last attempt or unrecoverable error, use fallback
                if attempt == max_retries - 1:
                    print("üîÑ All retry attempts exhausted, using fallback data")
                    return self.get_enhanced_fallback_data()
        
        # If we get here, all retries failed
        print("‚ùå Unable to fetch real tweets after all retries")
        return self.get_enhanced_fallback_data()

    def is_disaster_related(self, text: str) -> bool:
        """Check if tweet text is disaster-related"""
        if not text:
            return False
        
        text_lower = text.lower()
        
        # Primary disaster keywords
        disaster_keywords = [
            'earthquake', 'tsunami', 'flood', 'wildfire', 'hurricane', 'tornado',
            'cyclone', 'landslide', 'drought', 'volcano', 'avalanche', 'blizzard',
            'emergency', 'disaster', 'evacuation', 'rescue', 'alert', 'warning',
            'breaking', 'urgent', 'crisis', 'calamity', 'catastrophe'
        ]
        
        # Location + severity indicators
        severity_words = ['severe', 'major', 'massive', 'devastating', 'critical', 'urgent', 'breaking']
        location_words = ['city', 'area', 'region', 'district', 'state', 'country']
        
        # Check for primary disaster keywords
        if any(keyword in text_lower for keyword in disaster_keywords):
            return True
        
        # Check for severity + location combination
        has_severity = any(word in text_lower for word in severity_words)
        has_location = any(word in text_lower for word in location_words)
        
        if has_severity and has_location:
            return True
        
        return False

    def calculate_disaster_relevance_score(self, text: str) -> float:
        """Calculate disaster relevance score (0.0 to 1.0) for enhanced filtering"""
        if not text:
            return 0.0
        
        text_lower = text.lower()
        score = 0.0
        
        # High-impact disaster keywords (0.4 points each)
        high_impact_keywords = [
            'earthquake', 'tsunami', 'hurricane', 'tornado', 'wildfire', 
            'volcano', 'cyclone', 'avalanche', 'landslide'
        ]
        
        # Medium-impact keywords (0.3 points each)
        medium_impact_keywords = [
            'flood', 'storm', 'blizzard', 'drought', 'fire', 'emergency'
        ]
        
        # Low-impact but relevant keywords (0.2 points each)
        low_impact_keywords = [
            'disaster', 'crisis', 'evacuation', 'rescue', 'alert', 'warning', 'breaking'
        ]
        
        # Check for keyword matches
        for keyword in high_impact_keywords:
            if keyword in text_lower:
                score += 0.4
        
        for keyword in medium_impact_keywords:
            if keyword in text_lower:
                score += 0.3
                
        for keyword in low_impact_keywords:
            if keyword in text_lower:
                score += 0.2
        
        # Urgency multipliers
        urgency_words = ['urgent', 'immediate', 'critical', 'severe', 'major', 'massive']
        if any(word in text_lower for word in urgency_words):
            score *= 1.3
            
        # Location specificity bonus
        location_indicators = ['city', 'area', 'region', 'district', 'county', 'state']
        if any(word in text_lower for word in location_indicators):
            score += 0.1
        
        # Verified source bonus (if hashtags suggest official source)
        official_tags = ['#breaking', '#alert', '#emergency', '#official']
        if any(tag in text_lower for tag in official_tags):
            score += 0.15
        
        return min(score, 1.0)  # Cap at 1.0

    def search_realtime_hashtags(self, hashtags: List[str], max_results: int = 50) -> List[Dict]:
        """Enhanced hashtag search with robust error handling"""
        if not self.api_active:
            print("‚ùå Twitter API not active for hashtag search")
            return []
        
        max_retries = 2
        retry_delay = 10
        
        for attempt in range(max_retries):
            try:
                # Build hashtag query with enhanced targeting
                hashtag_query = ' OR '.join([f"#{tag}" for tag in hashtags[:5]])  # Limit to avoid long queries
                query = f"({hashtag_query}) -is:retweet lang:en has:geo"  # Prefer geo-tagged tweets
                
                print(f"üè∑Ô∏è Searching hashtags (Attempt {attempt + 1}): {hashtag_query}")
                
                tweets = self.twitter_client.search_recent_tweets(
                    query=query,
                    max_results=min(max_results, 30),  # Reduced to avoid rate limits
                    tweet_fields=['created_at', 'author_id', 'public_metrics', 'lang', 'geo'],
                    user_fields=['username', 'location', 'verified'],
                    expansions=['author_id']
                )
                
                if not tweets.data:
                    print("‚ö†Ô∏è No tweets found with disaster hashtags")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        continue
                    return []
                
                # Process results with enhanced data
                processed_tweets = []
                users_dict = {user.id: user for user in tweets.includes.get('users', [])} if tweets.includes else {}
                
                for tweet in tweets.data:
                    author_info = users_dict.get(tweet.author_id, None)
                    author_name = author_info.username if author_info else f"user_{tweet.author_id}"
                    
                    tweet_data = {
                        'id': str(tweet.id),
                        'text': tweet.text,
                        'content': tweet.text,
                        'author': author_name,
                        'author_name': author_info.name if author_info and hasattr(author_info, 'name') else 'Unknown',
                        'created_at': tweet.created_at.isoformat() if tweet.created_at else datetime.now().isoformat(),
                        'location': author_info.location if author_info and hasattr(author_info, 'location') else 'Unknown',
                        'hashtags': [f"#{tag}" for tag in hashtags if f"#{tag.lower()}" in tweet.text.lower()],
                        'retweet_count': tweet.public_metrics.get('retweet_count', 0) if tweet.public_metrics else 0,
                        'like_count': tweet.public_metrics.get('like_count', 0) if tweet.public_metrics else 0,
                        'reply_count': tweet.public_metrics.get('reply_count', 0) if tweet.public_metrics else 0,
                        'platform': 'twitter_hashtag_search',
                        'verified': author_info.verified if author_info and hasattr(author_info, 'verified') else False,
                        'disaster_score': self.calculate_disaster_relevance_score(tweet.text)
                    }
                    processed_tweets.append(tweet_data)
                
                # Sort by disaster relevance
                processed_tweets.sort(key=lambda x: x['disaster_score'], reverse=True)
                
                print(f"‚úÖ Found {len(processed_tweets)} tweets with disaster hashtags")
                return processed_tweets
                
            except Exception as e:
                error_str = str(e).lower()
                print(f"‚ùå Error searching hashtags (Attempt {attempt + 1}): {e}")
                
                if "503" in error_str or "service unavailable" in error_str:
                    print("üö´ Twitter API temporarily unavailable")
                elif "429" in error_str or "rate limit" in error_str:
                    print("‚è∞ Rate limited on hashtag search")
                
                if attempt < max_retries - 1:
                    print(f"‚è≥ Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                else:
                    return []
        
        return []

    def extract_hashtags_from_text(self, text: str) -> List[str]:
        """Extract hashtags from tweet text"""
        if not text:
            return []
        
        import re
        hashtags = re.findall(r'#(\w+)', text)
        return [f"#{tag}" for tag in hashtags]

    def extract_location(self, tweet, user) -> str:
        """Extract location information from tweet or user data"""
        location = "Unknown"
        
        # Try to get location from tweet geo data
        if hasattr(tweet, 'geo') and tweet.geo:
            location = "Geo-located"
        
        # Try to get from user location
        elif hasattr(user, 'location') and user.location:
            location = user.location
        
        # Extract from tweet text (basic location detection)
        elif tweet.text:
            # Simple location extraction for Indian cities/states
            indian_locations = [
                'mumbai', 'delhi', 'bangalore', 'hyderabad', 'chennai',
                'kolkata', 'pune', 'ahmedabad', 'jaipur', 'surat',
                'lucknow', 'kanpur', 'nagpur', 'patna', 'indore',
                'thane', 'bhopal', 'visakhapatnam', 'pimpri', 'vadodara',
                'india', 'maharashtra', 'karnataka', 'tamil nadu',
                'uttar pradesh', 'west bengal', 'rajasthan', 'gujarat'
            ]
            
            tweet_lower = tweet.text.lower()
            for loc in indian_locations:
                if loc in tweet_lower:
                    location = loc.title()
                    break
        
        return location

    def get_fallback_disaster_data(self) -> List[Dict]:
        """Generate fallback disaster data when API is unavailable"""
        current_time = datetime.now()
        
        fallback_tweets = [
            {
                'id': f'fallback_flood_{int(time.time())}',
                'text': f'Heavy flooding reported in Mumbai due to monsoon rains. Water logging in multiple areas. Emergency services responding. #Flood #Mumbai #Emergency #{current_time.strftime("%Y%m%d")}',
                'author': 'MumbaiAlerts',
                'created_at': current_time.isoformat(),
                'location': 'Mumbai, Maharashtra, India',
                'retweet_count': 45,
                'like_count': 120,
                'hashtags': ['#Flood', '#Mumbai', '#Emergency']
            },
            {
                'id': f'fallback_earthquake_{int(time.time())+1}',
                'text': f'Magnitude 6.2 earthquake strikes near Tokyo. Buildings shaking reported. No tsunami warning issued. Monitoring situation closely. #Earthquake #Tokyo #Breaking #{current_time.strftime("%Y%m%d")}',
                'author': 'EarthquakeAlert',
                'created_at': (current_time - timedelta(hours=2)).isoformat(),
                'location': 'Tokyo, Japan',
                'retweet_count': 234,
                'like_count': 445,
                'hashtags': ['#Earthquake', '#Tokyo', '#Breaking']
            },
            {
                'id': f'fallback_wildfire_{int(time.time())+2}',
                'text': f'Wildfire spreading rapidly in California. Evacuation orders issued for nearby communities. Air quality severely impacted. #Wildfire #California #Evacuation #{current_time.strftime("%Y%m%d")}',
                'author': 'CalFireUpdate',
                'created_at': (current_time - timedelta(hours=5)).isoformat(),
                'location': 'California, USA',
                'retweet_count': 167,
                'like_count': 289,
                'hashtags': ['#Wildfire', '#California', '#Evacuation']
            }
        ]
        
        return fallback_tweets

    def get_enhanced_fallback_data(self) -> List[Dict]:
        """Generate enhanced fallback disaster data with more variety and realism"""
        current_time = datetime.now()
        
        # More comprehensive fallback data with real-world scenarios
        enhanced_fallback_tweets = [
            {
                'id': f'enhanced_flood_{int(time.time())}',
                'text': f'BREAKING: Severe flooding in Mumbai suburbs after 200mm rainfall in 6 hours. Waterlogging reported in Andheri, Bandra. Local trains suspended. Emergency services deployed. #MumbaiFloods #Emergency #MonsoonAlert #{current_time.strftime("%Y%m%d")}',
                'content': f'BREAKING: Severe flooding in Mumbai suburbs after 200mm rainfall in 6 hours. Waterlogging reported in Andheri, Bandra. Local trains suspended. Emergency services deployed.',
                'author': 'MumbaiTrafficPolice',
                'author_name': 'Mumbai Traffic Police',
                'created_at': current_time.isoformat(),
                'location': 'Mumbai, Maharashtra, India',
                'retweet_count': 156,
                'like_count': 89,
                'reply_count': 34,
                'quote_count': 23,
                'hashtags': ['#MumbaiFloods', '#Emergency', '#MonsoonAlert'],
                'platform': 'enhanced_fallback',
                'verified': True,
                'disaster_score': 0.95
            },
            {
                'id': f'enhanced_earthquake_{int(time.time())+1}',
                'text': f'URGENT: Magnitude 6.4 earthquake reported 85km northeast of Tokyo at {(current_time - timedelta(hours=1)).strftime("%H:%M")} JST. Shaking felt across Kanto region. No immediate tsunami threat. Buildings evacuated as precaution. #JapanEarthquake #Tokyo #Breaking',
                'content': 'URGENT: Magnitude 6.4 earthquake reported 85km northeast of Tokyo. Shaking felt across Kanto region. No immediate tsunami threat.',
                'author': 'JMA_earthquakes',
                'author_name': 'Japan Meteorological Agency',
                'created_at': (current_time - timedelta(hours=1)).isoformat(),
                'location': 'Tokyo, Japan',
                'retweet_count': 892,
                'like_count': 234,
                'reply_count': 156,
                'quote_count': 67,
                'hashtags': ['#JapanEarthquake', '#Tokyo', '#Breaking'],
                'platform': 'enhanced_fallback',
                'verified': True,
                'disaster_score': 0.98
            },
            {
                'id': f'enhanced_wildfire_{int(time.time())+2}',
                'text': f'EVACUATION ORDER: Fast-moving wildfire near Santa Rosa, CA forces evacuation of 2,500 residents. Fire has consumed 1,200 acres in 4 hours. Multiple air tankers deployed. Highway 101 closed northbound. #CaliforniaWildfires #Evacuation #SantaRosa',
                'content': 'EVACUATION ORDER: Fast-moving wildfire near Santa Rosa, CA forces evacuation of 2,500 residents. Fire has consumed 1,200 acres in 4 hours.',
                'author': 'CAL_FIRE',
                'author_name': 'CAL FIRE',
                'created_at': (current_time - timedelta(hours=3)).isoformat(),
                'location': 'Santa Rosa, California, USA',
                'retweet_count': 543,
                'like_count': 178,
                'reply_count': 89,
                'quote_count': 45,
                'hashtags': ['#CaliforniaWildfires', '#Evacuation', '#SantaRosa'],
                'platform': 'enhanced_fallback',
                'verified': True,
                'disaster_score': 0.92
            },
            {
                'id': f'enhanced_cyclone_{int(time.time())+3}',
                'text': f'CYCLONE ALERT: Super Cyclone "Amphan" intensifies to Category 4, approaching Bangladesh coast. Wind speeds 240 kmph. 2.4 million people evacuated from coastal areas. Landfall expected tomorrow morning. #CycloneAmphan #Bangladesh #Emergency',
                'content': 'CYCLONE ALERT: Super Cyclone "Amphan" intensifies to Category 4, approaching Bangladesh coast. Wind speeds 240 kmph. 2.4 million people evacuated.',
                'author': 'BMD_Weather',
                'author_name': 'Bangladesh Meteorological Dept',
                'created_at': (current_time - timedelta(hours=6)).isoformat(),
                'location': 'Bangladesh',
                'retweet_count': 678,
                'like_count': 234,
                'reply_count': 123,
                'quote_count': 56,
                'hashtags': ['#CycloneAmphan', '#Bangladesh', '#Emergency'],
                'platform': 'enhanced_fallback',
                'verified': True,
                'disaster_score': 0.96
            },
            {
                'id': f'enhanced_landslide_{int(time.time())+4}',
                'text': f'RESCUE OPERATION: Major landslide blocks highway in Himachal Pradesh after heavy monsoon rains. 15 vehicles trapped, rescue teams deployed. Alternative routes being arranged. Weather warning remains in effect. #HimachalPradesh #Landslide #Rescue',
                'content': 'RESCUE OPERATION: Major landslide blocks highway in Himachal Pradesh after heavy monsoon rains. 15 vehicles trapped, rescue teams deployed.',
                'author': 'HP_StateDisaster',
                'author_name': 'HP State Disaster Management',
                'created_at': (current_time - timedelta(hours=8)).isoformat(),
                'location': 'Himachal Pradesh, India',
                'retweet_count': 234,
                'like_count': 145,
                'reply_count': 67,
                'quote_count': 23,
                'hashtags': ['#HimachalPradesh', '#Landslide', '#Rescue'],
                'platform': 'enhanced_fallback',
                'verified': True,
                'disaster_score': 0.89
            }
        ]
        
        print(f"üîÑ Using enhanced fallback disaster data with {len(enhanced_fallback_tweets)} realistic scenarios")
        print("üìä These are simulated but realistic disaster scenarios for system testing")
        
        return enhanced_fallback_tweets

# WhatsApp Service using Twilio
class TwilioWhatsAppService:
    """Enhanced WhatsApp messaging service using Twilio"""
    
    def __init__(self):
        """Initialize Twilio client with credentials from .env"""
        try:
            # Twilio credentials from environment
            self.account_sid = os.getenv('TWILIO_ACCOUNT_SID')
            self.auth_token = os.getenv('TWILIO_AUTH_TOKEN') 
            self.twilio_phone = os.getenv('TWILIO_PHONE_NUMBER')
            
            # Validate credentials
            if not all([self.account_sid, self.auth_token, self.twilio_phone]):
                print("‚ö†Ô∏è  Twilio credentials missing in .env file")
                print("üîÑ Will use PyWhatKit fallback for WhatsApp messaging")
                self.whatsapp_enabled = False
                return
            
            # Initialize Twilio client only if credentials are available
            self.client = Client(self.account_sid, self.auth_token)
            
            # Test Twilio connection
            try:
                # Validate account by fetching account info
                account = self.client.api.accounts(self.account_sid).fetch()
                print("‚úÖ Twilio WhatsApp service initialized successfully")
                print(f"üì± Twilio Account: {account.friendly_name}")
                print(f"ÔøΩ Twilio Phone: {self.twilio_phone}")
                self.whatsapp_enabled = True
                
            except Exception as validation_error:
                print(f"‚ö†Ô∏è  Twilio credentials validation failed: {validation_error}")
                print("üîÑ Will use PyWhatKit fallback for WhatsApp messaging")
                self.whatsapp_enabled = False
                
        except Exception as e:
            print(f"‚ùå Twilio WhatsApp setup failed: {e}")
            print("üîÑ Using PyWhatKit as primary WhatsApp service")
            self.whatsapp_enabled = False
    """Enhanced WhatsApp messaging service using Twilio"""
    
    def __init__(self):
        """Initialize Twilio client with credentials from .env"""
        try:
            # Twilio credentials from environment
            self.account_sid = os.getenv('TWILIO_ACCOUNT_SID')
            self.auth_token = os.getenv('TWILIO_AUTH_TOKEN') 
            self.twilio_phone = os.getenv('TWILIO_PHONE_NUMBER')
            
            # Validate credentials
            if not all([self.account_sid, self.auth_token, self.twilio_phone]):
                print("‚ö†Ô∏è  Twilio credentials missing in .env file")
                print("üîÑ Will use PyWhatKit fallback for WhatsApp messaging")
                self.whatsapp_enabled = False
                return
            
            # Initialize Twilio client only if credentials are available
            self.client = Client(self.account_sid, self.auth_token)
            
            # Test Twilio connection
            try:
                # Validate account by fetching account info
                account = self.client.api.accounts(self.account_sid).fetch()
                print("‚úÖ Twilio WhatsApp service initialized successfully")
                print(f"üì± Twilio Account: {account.friendly_name}")
                print(f"üì± Twilio Phone: {self.twilio_phone}")
                self.whatsapp_enabled = True
                
            except Exception as validation_error:
                print(f"‚ö†Ô∏è  Twilio credentials validation failed: {validation_error}")
                print("üîÑ Will use PyWhatKit fallback for WhatsApp messaging")
                self.whatsapp_enabled = False
                
        except Exception as e:
            print(f"‚ùå Twilio WhatsApp setup failed: {e}")
            print("üîÑ Using PyWhatKit as primary WhatsApp service")
            self.whatsapp_enabled = False
    
    def send_whatsapp_message(self, to_number: str, message: str) -> bool:
        """Send WhatsApp message using Twilio with enhanced error handling"""
        if not self.whatsapp_enabled:
            print("üì± Twilio not available, using PyWhatKit fallback...")
            return self.send_fallback_whatsapp(to_number, message)
        
        try:
            # Clean and format phone number
            clean_number = to_number.replace('-', '').replace(' ', '').replace('(', '').replace(')', '')
            if not clean_number.startswith('+'):
                clean_number = '+' + clean_number
            
            # Format for Twilio WhatsApp
            whatsapp_to = f"whatsapp:{clean_number}"
            whatsapp_from = f"whatsapp:{self.twilio_phone}"
            
            print(f"üì± Attempting Twilio WhatsApp send...")
            print(f"   To: {whatsapp_to}")
            print(f"   From: {whatsapp_from}")
            print(f"   Message length: {len(message)} characters")
            
            # Truncate message if too long (Twilio limit is 1600 chars)
            if len(message) > 1500:
                message = message[:1450] + "...\n\n[Message truncated for WhatsApp]"
                print(f"‚ö†Ô∏è  Message truncated to {len(message)} characters")
            
            # Send via Twilio
            message_obj = self.client.messages.create(
                body=message,
                from_=whatsapp_from,
                to=whatsapp_to
            )
            
            print(f"‚úÖ Twilio WhatsApp message sent successfully!")
            print(f"   Message SID: {message_obj.sid}")
            print(f"   Status: {message_obj.status}")
            
            return True
            
        except Exception as e:
            error_msg = str(e).lower()
            print(f"‚ùå Twilio WhatsApp failed: {e}")
            
            # Check for specific Twilio errors
            if "auth" in error_msg or "credentials" in error_msg:
                print("ÔøΩ Issue: Invalid Twilio credentials")
            elif "phone number" in error_msg:
                print("üîß Issue: Invalid phone number format")
            elif "whatsapp" in error_msg:
                print("üîß Issue: WhatsApp messaging not enabled for this Twilio number")
            elif "unverified" in error_msg:
                print("üîß Issue: Target phone number not verified in Twilio sandbox")
                
            print("üîÑ Trying PyWhatKit fallback...")
            return self.send_fallback_whatsapp(to_number, message)
    
    def send_fallback_whatsapp(self, to_number: str, message: str) -> bool:
        """Enhanced fallback WhatsApp sending using PyWhatKit"""
        try:
            print(f"üì± Sending WhatsApp via PyWhatKit fallback...")
            print(f"   To: {to_number}")
            print(f"   Message length: {len(message)} characters")
            
            # Clean phone number for PyWhatKit
            clean_number = to_number.replace('-', '').replace(' ', '').replace('(', '').replace(')', '')
            if not clean_number.startswith('+'):
                clean_number = '+' + clean_number
                
            print(f"   Cleaned number: {clean_number}")
            
            # Send instantly without waiting
            kit.sendwhatmsg_instantly(
                clean_number, 
                message, 
                wait_time=15,    # Wait 15 seconds for WhatsApp to load
                tab_close=True,  # Close tab after sending
                close_time=5     # Wait 5 seconds before closing
            )
            
            print(f"‚úÖ PyWhatKit WhatsApp message sent successfully!")
            print(f"üìã Message logged to PyWhatKit_DB.txt")
            
            return True
            
        except Exception as e:
            print(f"‚ùå PyWhatKit fallback also failed: {e}")
            print(f"üîç Possible issues:")
            print(f"   - WhatsApp Web not logged in")
            print(f"   - Chrome browser not available")
            print(f"   - Network connectivity issues")
            print(f"   - Invalid phone number format")
            
            # Show message content for debugging
            print(f"\nüìù MESSAGE CONTENT (for manual verification):")
            print(f"To: {to_number}")
            print(f"Message: {message[:200]}{'...' if len(message) > 200 else ''}")
            
            return False
    
    def test_whatsapp_service(self, test_phone: str = "+918104389398") -> bool:
        """Test WhatsApp messaging service with both Twilio and fallback"""
        test_message = """üß™ TEST MESSAGE - Enhanced Disaster Alert System

This is a test message to verify WhatsApp integration is working.

‚úÖ System Components:
üì± Twilio WhatsApp API
üîÑ PyWhatKit Fallback  
ü§ñ AI Disaster Detection
üóÑÔ∏è Database Logging

‚è∞ Test Time: """ + datetime.now().strftime('%d %b %Y, %H:%M:%S') + """

If you receive this, the system is working correctly! üéâ"""

        print(f"\nüß™ TESTING WHATSAPP SERVICE")
        print(f"‚ïê" * 40)
        print(f"üì± Test phone: {test_phone}")
        print(f"üìù Test message: {len(test_message)} characters")
        
        return self.send_whatsapp_message(test_phone, test_message)

class DisasterAI:
    """Enhanced AI system for disaster detection and classification"""
    
    def __init__(self):
        """Initialize Gemini AI with enhanced disaster detection"""
        self.ai_active = False
        self.model = None
        
        try:
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                print("‚ö†Ô∏è  GEMINI_API_KEY not found in .env file")
                print("üìù Add your Gemini API key to .env file:")
                print("   GEMINI_API_KEY=your_api_key_here")
                print("üîÑ System will use rule-based fallback for disaster detection")
                return
                
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            
            # Test the API with a simple request
            test_response = self.model.generate_content("Test")
            self.ai_active = True
            print("‚úÖ Gemini AI initialized and tested successfully")
            
        except Exception as e:
            error_str = str(e)
            print(f"‚ùå Gemini AI setup failed: {e}")
            
            if "SERVICE_DISABLED" in error_str:
                print("\nüîß GOOGLE GEMINI API FIX REQUIRED:")
                print("1. Visit: https://console.developers.google.com/apis/api/generativelanguage.googleapis.com/overview")
                print("2. Enable the 'Generative Language API'")
                print("3. Wait 2-3 minutes for activation")
                print("4. Restart the application")
                print("\nüîÑ Using rule-based fallback for now...")
            elif "PERMISSION_DENIED" in error_str or "auth" in error_str.lower():
                print("üîë API Key Authentication Issue:")
                print("- Check your GEMINI_API_KEY in .env file")
                print("- Ensure the API key is valid and active")
            elif "quota" in error_str.lower() or "limit" in error_str.lower():
                print("üìä API Quota/Rate Limit Issue:")
                print("- Check your Google AI Studio quota")
                print("- Wait a few minutes before retrying")
            
            print("ü§ñ System will use intelligent rule-based disaster detection")
            self.ai_active = False
    
    def check_api_status(self) -> bool:
        """Check if Gemini AI API is working"""
        if not self.ai_active:
            return False
        
        try:
            test_response = self.model.generate_content("Hello")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è  API Status Check Failed: {e}")
            return False
    
    def analyze_disaster_post(self, content: str, location: str, hashtags: List[str]) -> Optional[DisasterAlert]:
        """Analyze social media post for disaster information with enhanced context"""
        if not self.ai_active:
            return None
        
        try:
            # Enhanced prompt with stricter JSON formatting
            prompt = f"""You are a disaster detection AI. Analyze this social media post for disaster information.

Content: "{content}"
Location: {location}
Hashtags: {', '.join(hashtags) if hashtags else 'None'}

Respond ONLY with valid JSON in this exact format:
{{"is_disaster": true, "disaster_type": "flood", "confidence": 0.85, "severity": "high", "affected_radius_km": 25, "location": "Mumbai", "reasoning": "Heavy rainfall causing flooding"}}

Rules:
- is_disaster: true/false only
- disaster_type: earthquake, flood, fire, cyclone, landslide, storm, drought, tsunami, or unknown
- confidence: number 0.0-1.0 (minimum 0.7 for valid disasters)
- severity: low, medium, high, or critical
- affected_radius_km: number (reasonable estimate)
- location: specific place name
- reasoning: brief explanation (max 50 words)

JSON only, no other text:"""
            
            response = self.model.generate_content(prompt)
            response_text = response.text.strip()
            
            # Clean response text to extract JSON
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].strip()
            
            # Remove any extra text before/after JSON
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}')
            if start_idx != -1 and end_idx != -1:
                response_text = response_text[start_idx:end_idx+1]
            
            # Parse AI response
            try:
                result = json.loads(response_text)
                
                # Validate required fields
                if (result.get('is_disaster', False) and 
                    result.get('confidence', 0) >= 0.7 and
                    result.get('disaster_type', 'unknown') != 'unknown'):
                    
                    # Generate coordinates
                    lat, lon = self.get_coordinates(result.get('location', location))
                    
                    alert = DisasterAlert(
                        id=f"alert_{int(time.time())}_{hash(content[:50]) % 1000}",
                        disaster_type=result.get('disaster_type', 'unknown'),
                        location=result.get('location', location),
                        latitude=lat,
                        longitude=lon,
                        confidence_score=float(result.get('confidence', 0.0)),
                        timestamp=datetime.now(),
                        source_platform='social_media',
                        content=content,
                        author='social_user',
                        hashtags=hashtags,
                        severity_level=result.get('severity', 'medium'),
                        affected_radius_km=float(result.get('affected_radius_km', 10.0))
                    )
                    
                    print(f"‚úÖ AI detected {alert.disaster_type} with {alert.confidence_score:.0%} confidence")
                    return alert
                else:
                    print(f"‚ÑπÔ∏è AI: Not a disaster or low confidence ({result.get('confidence', 0):.2f})")
                
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è AI JSON parsing failed: {e}")
                print(f"üìù Raw response: {response_text[:100]}...")
                # Try fallback analysis
                return self.fallback_disaster_analysis(content, location, hashtags)
            
        except Exception as e:
            print(f"‚ùå AI analysis error: {e}")
            return self.fallback_disaster_analysis(content, location, hashtags)
        
        return None
    
    def fallback_disaster_analysis(self, content: str, location: str, hashtags: List[str]) -> Optional[DisasterAlert]:
        """Enhanced rule-based fallback when AI fails - now more intelligent"""
        try:
            content_lower = content.lower()
            
            # Enhanced disaster keywords with confidence scoring
            disaster_keywords = {
                'earthquake': {
                    'keywords': ['earthquake', 'tremor', 'seismic', 'richter', 'magnitude', 'aftershock', 'epicenter'],
                    'confidence': 0.9,
                    'severity': 'high'
                },
                'flood': {
                    'keywords': ['flood', 'flooding', 'waterlogged', 'inundation', 'heavy rain', 'monsoon', 'overflow', 'submerged'],
                    'confidence': 0.85,
                    'severity': 'medium'
                },
                'fire': {
                    'keywords': ['fire', 'wildfire', 'blaze', 'burning', 'flames', 'smoke', 'burn'],
                    'confidence': 0.8,
                    'severity': 'high'
                },
                'cyclone': {
                    'keywords': ['cyclone', 'hurricane', 'typhoon', 'storm', 'winds', 'landfall'],
                    'confidence': 0.85,
                    'severity': 'high'
                },
                'landslide': {
                    'keywords': ['landslide', 'mudslide', 'rockfall', 'slope failure', 'debris'],
                    'confidence': 0.8,
                    'severity': 'medium'
                },
                'tsunami': {
                    'keywords': ['tsunami', 'tidal wave', 'sea waves'],
                    'confidence': 0.95,
                    'severity': 'critical'
                },
                'tornado': {
                    'keywords': ['tornado', 'twister', 'funnel cloud'],
                    'confidence': 0.9,
                    'severity': 'high'
                }
            }
            
            # Emergency and severity indicators
            emergency_words = {
                'breaking': 0.3, 'urgent': 0.25, 'emergency': 0.3, 'alert': 0.2,
                'rescue': 0.25, 'evacuation': 0.3, 'disaster': 0.2, 'crisis': 0.25,
                'casualties': 0.3, 'injured': 0.2, 'trapped': 0.25, 'missing': 0.2,
                'damage': 0.15, 'destroyed': 0.25, 'collapsed': 0.3
            }
            
            # Location indicators (adds credibility)
            location_words = ['city', 'area', 'region', 'district', 'state', 'country', 'village', 'town']
            
            detected_type = None
            base_confidence = 0.0
            severity = 'medium'
            
            # Check for disaster types with enhanced scoring
            for disaster_type, data in disaster_keywords.items():
                type_score = 0
                for keyword in data['keywords']:
                    if keyword in content_lower:
                        type_score += 1
                
                # Calculate confidence based on keyword matches
                if type_score > 0:
                    keyword_confidence = min(type_score / len(data['keywords']), 1.0) * data['confidence']
                    if keyword_confidence > base_confidence:
                        detected_type = disaster_type
                        base_confidence = keyword_confidence
                        severity = data['severity']
            
            # Add emergency context bonus
            emergency_bonus = 0
            for word, bonus in emergency_words.items():
                if word in content_lower:
                    emergency_bonus += bonus
            
            # Add location context bonus
            location_bonus = 0
            if any(word in content_lower for word in location_words):
                location_bonus = 0.1
                
            # Add hashtag bonus
            hashtag_bonus = 0
            if hashtags:
                disaster_hashtags = ['earthquake', 'flood', 'fire', 'emergency', 'disaster', 'alert', 'breaking']
                for tag in hashtags:
                    if any(d_tag in tag.lower() for d_tag in disaster_hashtags):
                        hashtag_bonus += 0.1
            
            # Calculate final confidence
            final_confidence = base_confidence + min(emergency_bonus, 0.2) + location_bonus + min(hashtag_bonus, 0.15)
            
            print(f"ü§ñ RULE-BASED ANALYSIS:")
            print(f"   Type: {detected_type}")
            print(f"   Base confidence: {base_confidence:.2f}")
            print(f"   Emergency bonus: {emergency_bonus:.2f}")
            print(f"   Location bonus: {location_bonus:.2f}")
            print(f"   Hashtag bonus: {hashtag_bonus:.2f}")
            print(f"   Final confidence: {final_confidence:.2f}")
            
            if detected_type and final_confidence >= 0.7:
                # Get coordinates for location
                lat, lon = self.get_coordinates(location)
                
                return DisasterAlert(
                    id=f"fallback_{int(time.time())}_{detected_type}",
                    disaster_type=detected_type,
                    location=location,
                    latitude=lat,
                    longitude=lon,
                    confidence_score=min(final_confidence, 0.99),  # Cap at 99% for fallback
                    timestamp=datetime.now(),
                    source_platform="social_media",
                    content=content[:500],  # Limit content length
                    author="unknown",
                    hashtags=hashtags[:5] if hashtags else [],  # Limit hashtags
                    severity_level=severity,
                    affected_radius_km=25.0
                )
            else:
                print(f"ü§ñ RULE-BASED: Not enough confidence ({final_confidence:.2f} < 0.7)")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Enhanced fallback analysis error: {e}")
        
        return None
    
    def get_coordinates(self, location: str) -> Tuple[Optional[float], Optional[float]]:
        """Get coordinates for location using geocoding"""
        try:
            geolocator = Nominatim(user_agent="disaster_monitor")
            location_data = geolocator.geocode(location)
            
            if location_data:
                return location_data.latitude, location_data.longitude
            
            # Fallback coordinates for major Indian cities
            city_coords = {
                'mumbai': (19.0760, 72.8777),
                'delhi': (28.7041, 77.1025),
                'bangalore': (12.9716, 77.5946),
                'hyderabad': (17.3850, 78.4867),
                'chennai': (13.0827, 80.2707),
                'kolkata': (22.5726, 88.3639),
                'pune': (18.5204, 73.8567),
                'ahmedabad': (23.0225, 72.5714),
                'india': (20.5937, 78.9629)
            }
            
            location_lower = location.lower()
            for city, coords in city_coords.items():
                if city in location_lower:
                    return coords
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Geocoding error: {e}")
        
        return None, None

class EnhancedDisasterSystem:
    """Main enhanced disaster monitoring and alert system"""
    
    def __init__(self):
        """Initialize the enhanced disaster system"""
        print("üöÄ Initializing Enhanced Disaster Alert System...")
        
        # Initialize components
        self.twitter_monitor = RealTimeTwitterMonitor()
        self.whatsapp_service = TwilioWhatsAppService()
        self.ai_system = DisasterAI()
        
        # Database setup - using disaster_analysis.db for compatibility
        self.db_path = "disaster_analysis.db"
        self.init_enhanced_database()
        
        # Monitoring settings
        self.subscribers = []
        self.alert_queue = queue.Queue()
        self.is_monitoring = False
        self.processed_alerts = set()  # Track processed alerts to avoid duplicates
        self.last_monitoring_time = datetime.now()
        
        # Load existing subscribers from database
        self.load_subscribers()
        
        # Default subscriber (can be configured)
        if not self.subscribers:
            self.add_subscriber(
                name="System Admin",
                phone="+918104389398",  # From the existing system
                location="Mumbai, India",
                radius_km=50
            )
        
        print("‚úÖ Enhanced Disaster System initialized successfully!")
        print(f"üìç Database: {self.db_path}")
        print(f"üë• Active subscribers: {len(self.subscribers)}")
        
        # Display system component status
        print("\nüìä SYSTEM COMPONENT STATUS:")
        print(f"   ü§ñ AI Detection: {'‚úÖ ACTIVE' if self.ai_system.ai_active else '‚ö†Ô∏è FALLBACK (Rule-based analysis)'}")
        print(f"   üê¶ Twitter API: {'‚úÖ ACTIVE' if self.twitter_monitor.api_active else '‚ö†Ô∏è FALLBACK (Limited functionality)'}")
        print(f"   üì± WhatsApp: {'‚úÖ ACTIVE' if self.whatsapp_service.whatsapp_enabled else '‚ö†Ô∏è LIMITED (No notifications)'}")
    
    def init_enhanced_database(self):
        """Initialize enhanced database schema compatible with existing disaster_analysis.db format"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # First, check if the table exists and add missing columns
        cursor.execute("PRAGMA table_info(disaster_posts)")
        existing_columns = {row[1] for row in cursor.fetchall()}
        
        # Create disaster_posts table with all required columns
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS disaster_posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT UNIQUE,
                title TEXT,
                content TEXT,
                author TEXT,
                post_time TEXT,
                place TEXT,
                region TEXT,
                disaster_type TEXT,
                urgency_level INTEGER,
                confidence_level INTEGER,
                sources TEXT,
                approved BOOLEAN DEFAULT 1,
                latitude REAL,
                longitude REAL,
                severity_level TEXT,
                affected_radius_km REAL,
                source_platform TEXT,
                hashtags TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Add missing columns if table already exists
        columns_to_add = [
            ('latitude', 'REAL'),
            ('longitude', 'REAL'), 
            ('severity_level', 'TEXT'),
            ('affected_radius_km', 'REAL'),
            ('source_platform', 'TEXT'),
            ('hashtags', 'TEXT'),
            ('created_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP')
        ]
        
        for column_name, column_type in columns_to_add:
            if column_name not in existing_columns:
                try:
                    cursor.execute(f'ALTER TABLE disaster_posts ADD COLUMN {column_name} {column_type}')
                    print(f"‚úÖ Added missing column: {column_name}")
                except sqlite3.OperationalError as e:
                    if "duplicate column name" not in str(e):
                        print(f"‚ö†Ô∏è Could not add column {column_name}: {e}")
        
        # Ensure approved column has default value
        if 'approved' in existing_columns:
            cursor.execute('UPDATE disaster_posts SET approved = 1 WHERE approved IS NULL')
        
        # Enhanced disaster alerts table (for internal tracking)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS disaster_alerts (
                id TEXT PRIMARY KEY,
                disaster_type TEXT NOT NULL,
                location TEXT NOT NULL,
                latitude REAL,
                longitude REAL,
                confidence_score REAL NOT NULL,
                timestamp TEXT NOT NULL,
                source_platform TEXT NOT NULL,
                content TEXT NOT NULL,
                author TEXT,
                hashtags TEXT,
                severity_level TEXT NOT NULL,
                affected_radius_km REAL NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create subscribers table for notification management
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS subscribers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                phone TEXT NOT NULL,
                location TEXT NOT NULL,
                latitude REAL,
                longitude REAL,
                radius_km REAL DEFAULT 50,
                active BOOLEAN DEFAULT 1,
                notifications_sent INTEGER DEFAULT 0,
                last_notified TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create notification log table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS notification_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                alert_id TEXT NOT NULL,
                subscriber_phone TEXT NOT NULL,
                status TEXT NOT NULL,
                sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("‚úÖ Enhanced database schema initialized with disaster_analysis.db compatibility")
    
    def add_subscriber(self, name: str, phone: str, location: str, radius_km: float = 50):
        """Add a new subscriber"""
        try:
            # Get coordinates for location
            ai_coords = self.ai_system.get_coordinates(location)
            lat, lon = ai_coords if ai_coords[0] is not None else (19.0760, 72.8777)
            
            subscriber = {
                'name': name,
                'phone': phone,
                'location': location,
                'latitude': lat,
                'longitude': lon,
                'radius_km': radius_km,
                'notifications_sent': 0,
                'last_notified': None
            }
            
            self.subscribers.append(subscriber)
            
            # Save to database
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO subscribers (name, phone, location, latitude, longitude, radius_km)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (name, phone, location, lat, lon, radius_km))
            conn.commit()
            conn.close()
            
            print(f"‚úÖ Added subscriber: {name} ({phone})")
            
        except Exception as e:
            print(f"‚ùå Error adding subscriber: {e}")
    
    def load_subscribers(self):
        """Load existing subscribers from database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT name, phone, location, latitude, longitude, radius_km 
                FROM subscribers 
                WHERE active = 1
            ''')
            
            for row in cursor.fetchall():
                subscriber = {
                    'name': row[0],
                    'phone': row[1],
                    'location': row[2],
                    'latitude': row[3],
                    'longitude': row[4],
                    'radius_km': row[5],
                    'notifications_sent': 0,
                    'last_notified': None
                }
                self.subscribers.append(subscriber)
            
            conn.close()
            print(f"‚úÖ Loaded {len(self.subscribers)} subscribers from database")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading subscribers: {e}")
    
    def store_alert_enhanced(self, alert: DisasterAlert):
        """Enhanced alert storage with continuous database updates and proper default values"""
        try:
            # Skip if we've already processed this alert
            alert_key = f"{alert.id}_{alert.timestamp.isoformat()}"
            if alert_key in self.processed_alerts:
                return
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ensure all fields have proper default values
            latitude = getattr(alert, 'latitude', None) if hasattr(alert, 'latitude') and alert.latitude is not None else 0.0
            longitude = getattr(alert, 'longitude', None) if hasattr(alert, 'longitude') and alert.longitude is not None else 0.0
            severity_level = getattr(alert, 'severity_level', None) if hasattr(alert, 'severity_level') and alert.severity_level else 'medium'
            affected_radius_km = getattr(alert, 'affected_radius_km', None) if hasattr(alert, 'affected_radius_km') and alert.affected_radius_km is not None else 25.0
            source_platform = getattr(alert, 'source_platform', None) if hasattr(alert, 'source_platform') and alert.source_platform else 'unknown'
            hashtags = getattr(alert, 'hashtags', []) if hasattr(alert, 'hashtags') and alert.hashtags else []
            author = getattr(alert, 'author', None) if hasattr(alert, 'author') and alert.author else 'system'
            content = getattr(alert, 'content', None) if hasattr(alert, 'content') and alert.content else f"{alert.disaster_type.title()} Alert - {alert.location}"
            
            # Store in disaster_posts table (primary format for visualizations/dashboard)
            cursor.execute('''
                INSERT OR REPLACE INTO disaster_posts 
                (post_id, title, content, author, post_time, place, region, 
                 disaster_type, urgency_level, confidence_level, sources, approved,
                 latitude, longitude, severity_level, affected_radius_km, source_platform, hashtags)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                alert.id,  # post_id
                f"{alert.disaster_type.title()} Alert - {alert.location}",  # title
                content,  # content with default
                author,  # author with default
                alert.timestamp.isoformat(),  # post_time
                alert.location if hasattr(alert, 'location') and alert.location else 'Unknown Location',  # place
                self._extract_region_from_location(alert.location if hasattr(alert, 'location') and alert.location else ''),  # region
                alert.disaster_type if hasattr(alert, 'disaster_type') and alert.disaster_type else 'unknown',  # disaster_type
                self._severity_to_urgency_level(severity_level),  # urgency_level (1-3)
                int((alert.confidence_score if hasattr(alert, 'confidence_score') and alert.confidence_score else 0.5) * 100),  # confidence_level as percentage
                json.dumps([source_platform]),  # sources as JSON array
                True,  # approved (auto-approve AI validated alerts)
                latitude,  # latitude with default
                longitude,  # longitude with default
                severity_level,  # severity_level with default
                affected_radius_km,  # affected_radius_km with default
                source_platform,  # source_platform with default
                ','.join(hashtags) if hashtags else 'disaster,alert'  # hashtags with default
            ))
            
            # Store in disaster_alerts table (internal tracking)
            cursor.execute('''
                INSERT OR REPLACE INTO disaster_alerts 
                (id, disaster_type, location, latitude, longitude, confidence_score, 
                 timestamp, source_platform, content, author, hashtags, severity_level, affected_radius_km)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                alert.id, 
                alert.disaster_type if hasattr(alert, 'disaster_type') and alert.disaster_type else 'unknown', 
                alert.location if hasattr(alert, 'location') and alert.location else 'Unknown Location', 
                latitude, 
                longitude,
                alert.confidence_score if hasattr(alert, 'confidence_score') and alert.confidence_score else 0.5, 
                alert.timestamp.isoformat(), 
                source_platform,
                content, 
                author, 
                ','.join(hashtags) if hashtags else 'disaster,alert', 
                severity_level,
                affected_radius_km
            ))
            
            conn.commit()
            conn.close()
            
            # Mark as processed
            self.processed_alerts.add(alert_key)
            
            # Clean old processed alerts (keep last 1000)
            if len(self.processed_alerts) > 1000:
                old_alerts = list(self.processed_alerts)[:500]  # Remove oldest half
                for old_alert in old_alerts:
                    self.processed_alerts.remove(old_alert)
            
            print(f"‚úÖ Enhanced alert stored: {alert.id} | {alert.disaster_type.upper()} in {alert.location}")
            
            # Update database statistics in real-time
            self._update_monitoring_stats()
            
        except Exception as e:
            print(f"‚ùå Error storing enhanced alert: {e}")
            import traceback
            traceback.print_exc()
    
    def _update_monitoring_stats(self):
        """Update real-time monitoring statistics"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Get recent statistics for logging
            cursor.execute('''
                SELECT COUNT(*) FROM disaster_posts 
                WHERE datetime(created_at) > datetime('now', '-24 hours') AND approved = 1
            ''')
            recent_count = cursor.fetchone()[0]
            
            cursor.execute('''
                SELECT disaster_type, COUNT(*) 
                FROM disaster_posts 
                WHERE datetime(created_at) > datetime('now', '-24 hours') AND approved = 1
                GROUP BY disaster_type
            ''')
            recent_by_type = dict(cursor.fetchall())
            
            conn.close()
            
            if recent_count > 0:
                print(f"üìä 24h Stats: {recent_count} alerts | Top types: {recent_by_type}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Stats update error: {e}")
    
    def get_recent_alerts_from_db(self, hours: int = 24) -> List[Dict]:
        """Get recent alerts from database for continuous monitoring"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM disaster_posts 
                WHERE datetime(post_time) > datetime('now', '-{} hours') 
                AND approved = 1
                ORDER BY post_time DESC
            '''.format(hours))
            
            columns = [desc[0] for desc in cursor.description]
            results = []
            
            for row in cursor.fetchall():
                data = dict(zip(columns, row))
                results.append(data)
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"‚ùå Error fetching recent alerts: {e}")
            return []
    def store_alert(self, alert: DisasterAlert):
        """Store disaster alert - wrapper for enhanced storage"""
        self.store_alert_enhanced(alert)
    
    def _extract_region_from_location(self, location: str) -> str:
        """Extract region from location string with proper default handling"""
        if not location or not isinstance(location, str):
            return 'unknown'
            
        location_lower = location.lower()
        
        # Asia
        if any(country in location_lower for country in [
            'india', 'pakistan', 'bangladesh', 'nepal', 'sri lanka', 'bhutan',
            'china', 'japan', 'korea', 'thailand', 'vietnam', 'indonesia',
            'malaysia', 'singapore', 'philippines', 'myanmar', 'cambodia',
            'laos', 'mongolia', 'taiwan', 'afghanistan'
        ]):
            return 'asia'
            
        # North America
        elif any(country in location_lower for country in [
            'usa', 'america', 'united states', 'canada', 'mexico',
            'guatemala', 'belize', 'el salvador', 'honduras', 'nicaragua',
            'costa rica', 'panama', 'cuba', 'jamaica', 'haiti', 'dominican'
        ]):
            return 'north_america'
            
        # South America
        elif any(country in location_lower for country in [
            'brazil', 'argentina', 'colombia', 'venezuela', 'peru', 'ecuador',
            'chile', 'bolivia', 'paraguay', 'uruguay', 'guyana', 'suriname'
        ]):
            return 'south_america'
            
        # Europe
        elif any(country in location_lower for country in [
            'uk', 'britain', 'england', 'scotland', 'wales', 'ireland',
            'france', 'germany', 'italy', 'spain', 'netherlands', 'belgium',
            'switzerland', 'austria', 'poland', 'czech', 'hungary', 'romania',
            'bulgaria', 'greece', 'portugal', 'sweden', 'norway', 'denmark',
            'finland', 'estonia', 'latvia', 'lithuania', 'slovakia', 'slovenia',
            'croatia', 'serbia', 'bosnia', 'montenegro', 'macedonia', 'albania',
            'russia', 'ukraine', 'belarus', 'moldova'
        ]):
            return 'europe'
            
        # Africa
        elif any(country in location_lower for country in [
            'nigeria', 'kenya', 'uganda', 'tanzania', 'rwanda', 'burundi',
            'congo', 'cameroon', 'chad', 'sudan', 'south sudan', 'ethiopia',
            'somalia', 'djibouti', 'eritrea', 'egypt', 'libya', 'tunisia',
            'algeria', 'morocco', 'mauritania', 'mali', 'niger', 'burkina faso',
            'senegal', 'gambia', 'guinea', 'sierra leone', 'liberia', 'ivory coast',
            'ghana', 'togo', 'benin', 'gabon', 'equatorial guinea', 'sao tome',
            'cape verde', 'angola', 'zambia', 'malawi', 'mozambique', 'zimbabwe',
            'botswana', 'namibia', 'south africa', 'lesotho', 'swaziland', 'madagascar'
        ]):
            return 'africa'
            
        # Oceania
        elif any(country in location_lower for country in [
            'australia', 'new zealand', 'fiji', 'papua new guinea', 'solomon islands',
            'vanuatu', 'samoa', 'tonga', 'micronesia', 'palau', 'marshall islands',
            'nauru', 'tuvalu', 'kiribati'
        ]):
            return 'oceania'
            
        # Middle East
        elif any(country in location_lower for country in [
            'saudi arabia', 'iran', 'iraq', 'kuwait', 'qatar', 'uae',
            'bahrain', 'oman', 'yemen', 'jordan', 'lebanon', 'syria',
            'israel', 'palestine', 'turkey', 'cyprus'
        ]):
            return 'middle_east'
            
        else:
            return 'unknown'
    
    def _severity_to_urgency_level(self, severity: str) -> int:
        """Convert severity level to urgency level (1-3) with proper default handling"""
        if not severity or not isinstance(severity, str):
            return 2  # Default to medium urgency
            
        severity_map = {
            'low': 1,
            'medium': 2,
            'high': 3,
            'critical': 3,
            'emergency': 3,
            'severe': 3,
            'minor': 1,
            'moderate': 2,
            'major': 3
        }
        return severity_map.get(severity.lower().strip(), 2)  # Default to medium (2)
    
    def calculate_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """Calculate distance between two coordinates using Haversine formula"""
        from math import radians, cos, sin, asin, sqrt
        
        # Convert to radians
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        
        # Haversine formula
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * asin(sqrt(a))
        km = 6371 * c  # Earth's radius in kilometers
        
        return km
    
    def should_notify_subscriber(self, subscriber: Dict, alert: DisasterAlert) -> bool:
        """Check if subscriber should be notified about alert"""
        # Check confidence threshold
        if alert.confidence_score < 0.8:
            return False
        
        # Check location proximity
        if alert.latitude and alert.longitude:
            distance = self.calculate_distance(
                subscriber['latitude'], subscriber['longitude'],
                alert.latitude, alert.longitude
            )
            
            if distance <= subscriber['radius_km']:
                return True
        
        # Check location name match
        if subscriber['location'].lower() in alert.location.lower():
            return True
        
        return False
    
    def format_alert_message(self, alert: DisasterAlert) -> str:
        """Format disaster alert for WhatsApp message"""
        severity_emoji = {
            'low': 'üü°',
            'medium': 'üü†',
            'high': 'üî¥',
            'critical': '‚ö´'
        }
        
        emoji = severity_emoji.get(alert.severity_level, 'üü†')
        
        message = f"""üö® DISASTER ALERT {emoji}

üìç {alert.disaster_type.upper()} in {alert.location}
üéØ AI Confidence: {alert.confidence_score:.0%}
‚ö° Severity: {alert.severity_level.upper()}
‚è∞ Time: {alert.timestamp.strftime('%d %b %Y, %H:%M:%S')}
üìä Affected Radius: ~{alert.affected_radius_km:.0f}km

üìã Details: {alert.content[:200]}{"..." if len(alert.content) > 200 else ""}

‚ö†Ô∏è SAFETY ACTIONS:
‚Ä¢ Stay indoors if possible
‚Ä¢ Follow local emergency services
‚Ä¢ Keep emergency contacts ready
‚Ä¢ Monitor news for updates

üö® Emergency Numbers:
üìû Emergency: 112
üöë Ambulance: 108
üöí Fire: 101

Stay Safe!
- Enhanced Disaster Alert System"""

        return message
    
    def send_notifications(self, alert: DisasterAlert):
        """Send notifications to relevant subscribers"""
        notifications_sent = 0
        
        for subscriber in self.subscribers:
            if self.should_notify_subscriber(subscriber, alert):
                try:
                    message = self.format_alert_message(alert)
                    
                    print(f"\nüì§ Sending alert to {subscriber['name']}")
                    print(f"   Phone: {subscriber['phone']}")
                    
                    success = self.whatsapp_service.send_whatsapp_message(
                        subscriber['phone'], message
                    )
                    
                    if success:
                        subscriber['notifications_sent'] += 1
                        subscriber['last_notified'] = datetime.now()
                        notifications_sent += 1
                        
                        # Log notification
                        self.log_notification(alert.id, subscriber['phone'], 'sent')
                        print(f"‚úÖ Notification sent successfully!")
                    else:
                        self.log_notification(alert.id, subscriber['phone'], 'failed')
                        print(f"‚ùå Notification failed")
                        
                except Exception as e:
                    print(f"‚ùå Notification error: {e}")
                    self.log_notification(alert.id, subscriber['phone'], 'error')
        
        return notifications_sent
    
    def log_notification(self, alert_id: str, phone: str, status: str):
        """Log notification attempt"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO notification_log (alert_id, subscriber_phone, status)
                VALUES (?, ?, ?)
            ''', (alert_id, phone, status))
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Logging error: {e}")
    
    def monitor_twitter_disasters_enhanced(self, days_back: int = 7):
        """Enhanced Twitter disaster monitoring with continuous database updates"""
        print(f"\nüê¶ Starting Enhanced Twitter Disaster Monitoring...")
        print(f"üìä Checking for disasters in last {days_back} days")
        print(f"ÔøΩ Last monitoring: {self.last_monitoring_time.strftime('%H:%M:%S')}")
        
        # Fetch tweets with enhanced error handling
        try:
            tweets = self.twitter_monitor.fetch_disaster_tweets(days_back)
            
            # Ensure tweets is always a list
            if tweets is None:
                print("‚ö†Ô∏è No tweets returned, using empty list")
                tweets = []
            elif not isinstance(tweets, list):
                print("‚ö†Ô∏è Invalid tweets format, using empty list") 
                tweets = []
                
        except Exception as e:
            print(f"‚ùå Error in fetch_disaster_tweets: {e}")
            tweets = []
        
        alerts_generated = 0
        alerts_stored = 0
        
        if not tweets:
            print("‚ÑπÔ∏è No tweets to analyze")
            return {'analyzed': 0, 'generated': 0, 'stored': 0}
        
        print(f"üîç Analyzing {len(tweets)} tweets...")
        
        for i, tweet_data in enumerate(tweets, 1):
            try:
                if i % 10 == 0:  # Progress indicator
                    print(f"   Progress: {i}/{len(tweets)} tweets processed...")
                
                # Analyze with AI
                alert = self.ai_system.analyze_disaster_post(
                    content=tweet_data['text'],
                    location=tweet_data['location'],
                    hashtags=tweet_data['hashtags']
                )
                
                if alert:
                    alerts_generated += 1
                    
                    # Store in database continuously
                    self.store_alert_enhanced(alert)
                    alerts_stored += 1
                    
                    # Send notifications to relevant subscribers
                    notifications_sent = self.send_notifications(alert)
                    
                    print(f"üö® ALERT {alerts_generated}: {alert.disaster_type.upper()} | {alert.location} | Confidence: {alert.confidence_score:.0%}")
                    if notifications_sent > 0:
                        print(f"   üì± Notifications sent: {notifications_sent}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error processing tweet {i}: {e}")
        
        # Update monitoring time
        self.last_monitoring_time = datetime.now()
        
        # Summary
        print(f"\nüìä ENHANCED MONITORING COMPLETE:")
        print(f"   üìù Tweets analyzed: {len(tweets)}")
        print(f"   üö® Alerts generated: {alerts_generated}")
        print(f"   üíæ Alerts stored in DB: {alerts_stored}")
        print(f"   üìà Success rate: {(alerts_generated/len(tweets)*100):.1f}%" if tweets else "0%")
        
        # Show recent database statistics
        self.show_database_summary()
        
        return {
            'analyzed': len(tweets),
            'generated': alerts_generated,
            'stored': alerts_stored
        }
    
    def show_database_summary(self):
        """Show current database summary statistics"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Check if created_at column exists
            cursor.execute("PRAGMA table_info(disaster_posts)")
            columns = {row[1] for row in cursor.fetchall()}
            has_created_at = 'created_at' in columns
            
            # Total disasters
            cursor.execute('SELECT COUNT(*) FROM disaster_posts WHERE approved = 1')
            total = cursor.fetchone()[0]
            
            # Recent disasters (24h) - use appropriate time column
            if has_created_at:
                time_condition = "datetime(created_at) > datetime('now', '-24 hours')"
            else:
                time_condition = "datetime(post_time) > datetime('now', '-24 hours')"
                
            cursor.execute(f'''
                SELECT COUNT(*) FROM disaster_posts 
                WHERE {time_condition} AND approved = 1
            ''')
            recent_24h = cursor.fetchone()[0]
            
            # By type (recent)
            cursor.execute(f'''
                SELECT disaster_type, COUNT(*) 
                FROM disaster_posts 
                WHERE {time_condition} AND approved = 1
                GROUP BY disaster_type 
                ORDER BY COUNT(*) DESC
                LIMIT 5
            ''')
            recent_types = dict(cursor.fetchall())
            
            # By region (recent)
            cursor.execute(f'''
                SELECT region, COUNT(*) 
                FROM disaster_posts 
                WHERE {time_condition} AND approved = 1
                GROUP BY region 
                ORDER BY COUNT(*) DESC
                LIMIT 3
            ''')
            recent_regions = dict(cursor.fetchall())
            
            conn.close()
            
            print(f"\nüíæ DATABASE SUMMARY:")
            print(f"   üìä Total disasters: {total}")
            print(f"   üïí Recent (24h): {recent_24h}")
            if recent_types:
                print(f"   üè∑Ô∏è Top types (24h): {recent_types}")
            if recent_regions:
                print(f"   üåç Top regions (24h): {recent_regions}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Database summary error: {e}")

    def monitor_twitter_disasters(self, days_back: int = 30):
        """Monitor Twitter for disaster posts - legacy method, now calls enhanced version"""
        result = self.monitor_twitter_disasters_enhanced(days_back)
        return result.get('generated', 0)  # Return count for backward compatibility
    
    def start_continuous_monitoring(self, check_interval_minutes: int = 30):
        """Enhanced continuous monitoring loop with database integration"""
        print(f"\nüöÄ STARTING ENHANCED CONTINUOUS MONITORING")
        print(f"   Check interval: {check_interval_minutes} minutes")
        print(f"   Subscribers: {len(self.subscribers)}")
        print(f"   Database: {self.db_path}")
        print(f"   Processed alerts cache: {len(self.processed_alerts)}")
        
        self.is_monitoring = True
        monitoring_cycle = 0
        
        try:
            while self.is_monitoring:
                monitoring_cycle += 1
                cycle_start = datetime.now()
                
                print(f"\n‚è∞ CYCLE {monitoring_cycle} - {cycle_start.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"=" * 50)
                
                # Enhanced Twitter monitoring
                try:
                    result = self.monitor_twitter_disasters_enhanced(days_back=1)  # Check last day
                    
                    alerts_generated = result.get('generated', 0)
                    alerts_stored = result.get('stored', 0)
                    
                    if alerts_generated > 0:
                        print(f"üö® Cycle {monitoring_cycle}: Generated {alerts_generated} alerts, stored {alerts_stored}")
                    else:
                        print(f"‚ÑπÔ∏è Cycle {monitoring_cycle}: No new alerts this cycle")
                        
                except Exception as e:
                    print(f"‚ùå Monitoring error in cycle {monitoring_cycle}: {e}")
                
                # Database maintenance (every 10 cycles)
                if monitoring_cycle % 10 == 0:
                    print(f"\nüîß MAINTENANCE - Cycle {monitoring_cycle}")
                    self.perform_database_maintenance()
                
                # Status update (every 5 cycles)
                if monitoring_cycle % 5 == 0:
                    print(f"\nüìä STATUS UPDATE - Cycle {monitoring_cycle}")
                    self.get_enhanced_system_status()
                
                # Wait for next check with progress indicator
                cycle_end = datetime.now()
                cycle_duration = (cycle_end - cycle_start).total_seconds()
                
                print(f"\n‚è≥ Cycle {monitoring_cycle} completed in {cycle_duration:.1f}s")
                print(f"‚è≥ Next check in {check_interval_minutes} minutes...")
                
                # Sleep with periodic status updates
                sleep_intervals = max(1, check_interval_minutes // 5)  # Update every 1/5 of interval
                sleep_per_interval = check_interval_minutes * 60 // sleep_intervals
                
                for i in range(sleep_intervals):
                    if not self.is_monitoring:
                        break
                    time.sleep(sleep_per_interval)
                    if i < sleep_intervals - 1:  # Don't show on last interval
                        remaining_minutes = ((sleep_intervals - i - 1) * sleep_per_interval) // 60
                        print(f"‚è≥ {remaining_minutes + 1} minutes until next cycle...")
                
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Monitoring stopped by user (Ctrl+C)")
        except Exception as e:
            print(f"‚ùå Critical monitoring error: {e}")
        finally:
            self.is_monitoring = False
            print(f"\nüèÅ MONITORING STOPPED")
            print(f"   Total cycles completed: {monitoring_cycle}")
            print(f"   Processed alerts: {len(self.processed_alerts)}")
            
    def perform_database_maintenance(self):
        """Perform routine database maintenance including NULL value cleanup"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            print("üîß Starting comprehensive database maintenance...")
            
            # Update NULL values with proper defaults in disaster_posts table
            print("   Updating NULL latitude values...")
            cursor.execute('UPDATE disaster_posts SET latitude = 0.0 WHERE latitude IS NULL')
            
            print("   Updating NULL longitude values...")
            cursor.execute('UPDATE disaster_posts SET longitude = 0.0 WHERE longitude IS NULL')
            
            print("   Updating NULL severity_level values...")
            cursor.execute('UPDATE disaster_posts SET severity_level = "medium" WHERE severity_level IS NULL')
            
            print("   Updating NULL affected_radius_km values...")
            cursor.execute('UPDATE disaster_posts SET affected_radius_km = 25.0 WHERE affected_radius_km IS NULL')
            
            print("   Updating NULL source_platform values...")
            cursor.execute('UPDATE disaster_posts SET source_platform = "unknown" WHERE source_platform IS NULL')
            
            print("   Updating NULL hashtags values...")
            cursor.execute('UPDATE disaster_posts SET hashtags = "disaster,alert" WHERE hashtags IS NULL OR hashtags = ""')
            
            print("   Updating NULL author values...")
            cursor.execute('UPDATE disaster_posts SET author = "system" WHERE author IS NULL OR author = ""')
            
            print("   Updating NULL place values...")
            cursor.execute('UPDATE disaster_posts SET place = "Unknown Location" WHERE place IS NULL OR place = ""')
            
            print("   Updating NULL region values...")
            cursor.execute('UPDATE disaster_posts SET region = "unknown" WHERE region IS NULL OR region = ""')
            
            print("   Updating NULL disaster_type values...")
            cursor.execute('UPDATE disaster_posts SET disaster_type = "unknown" WHERE disaster_type IS NULL OR disaster_type = ""')
            
            print("   Updating NULL urgency_level values...")
            cursor.execute('UPDATE disaster_posts SET urgency_level = 2 WHERE urgency_level IS NULL')
            
            print("   Updating NULL confidence_level values...")
            cursor.execute('UPDATE disaster_posts SET confidence_level = 50 WHERE confidence_level IS NULL')
            
            print("   Updating NULL sources values...")
            cursor.execute('UPDATE disaster_posts SET sources = "[]" WHERE sources IS NULL OR sources = ""')
            
            print("   Updating NULL approved values...")
            cursor.execute('UPDATE disaster_posts SET approved = 1 WHERE approved IS NULL')
            
            # Update NULL values in disaster_alerts table
            print("   Updating disaster_alerts table...")
            cursor.execute('UPDATE disaster_alerts SET latitude = 0.0 WHERE latitude IS NULL')
            cursor.execute('UPDATE disaster_alerts SET longitude = 0.0 WHERE longitude IS NULL')
            cursor.execute('UPDATE disaster_alerts SET severity_level = "medium" WHERE severity_level IS NULL')
            cursor.execute('UPDATE disaster_alerts SET affected_radius_km = 25.0 WHERE affected_radius_km IS NULL')
            cursor.execute('UPDATE disaster_alerts SET hashtags = "disaster,alert" WHERE hashtags IS NULL OR hashtags = ""')
            cursor.execute('UPDATE disaster_alerts SET author = "system" WHERE author IS NULL OR author = ""')
            
            # Clean old notification logs (keep last 1000)
            print("   Cleaning old notification logs...")
            cursor.execute('''
                DELETE FROM notification_log 
                WHERE id NOT IN (
                    SELECT id FROM notification_log 
                    ORDER BY sent_at DESC 
                    LIMIT 1000
                )
            ''')
            
            # Optimize database
            print("   Optimizing database...")
            cursor.execute('VACUUM')
            
            # Update statistics
            print("   Updating database statistics...")
            cursor.execute('ANALYZE')
            
            conn.commit()
            conn.close()
            
            print("‚úÖ Database maintenance completed successfully")
            print("   All NULL values have been replaced with appropriate defaults")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Database maintenance error: {e}")
            import traceback
            traceback.print_exc()
    
    def get_enhanced_system_status(self):
        """Get enhanced comprehensive system status with database insights"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Disaster posts statistics
            cursor.execute("SELECT COUNT(*) FROM disaster_posts WHERE approved = 1")
            total_disasters = cursor.fetchone()[0]
            
            # Disaster alerts statistics  
            cursor.execute("SELECT COUNT(*) FROM disaster_alerts")
            total_alerts = cursor.fetchone()[0]
            
            # Notification statistics
            cursor.execute("SELECT COUNT(*) FROM notification_log WHERE status = 'sent'")
            notifications_sent = cursor.fetchone()[0]
            
            # Recent activity (24h)
            cursor.execute('''
                SELECT COUNT(*) FROM disaster_posts 
                WHERE datetime(created_at) > datetime('now', '-24 hours') AND approved = 1
            ''')
            disasters_24h = cursor.fetchone()[0]
            
            # Recent activity (1h)  
            cursor.execute('''
                SELECT COUNT(*) FROM disaster_posts 
                WHERE datetime(created_at) > datetime('now', '-1 hour') AND approved = 1
            ''')
            disasters_1h = cursor.fetchone()[0]
            
            # Top disaster types (recent)
            cursor.execute('''
                SELECT disaster_type, COUNT(*) as count
                FROM disaster_posts 
                WHERE datetime(created_at) > datetime('now', '-24 hours') AND approved = 1
                GROUP BY disaster_type 
                ORDER BY count DESC
                LIMIT 5
            ''')
            top_types = cursor.fetchall()
            
            # Database size
            cursor.execute("PRAGMA page_count")
            page_count = cursor.fetchone()[0]
            cursor.execute("PRAGMA page_size")
            page_size = cursor.fetchone()[0]
            db_size_mb = (page_count * page_size) / (1024 * 1024)
            
            conn.close()
            
            # Display status
            print(f"\nüìä ENHANCED SYSTEM STATUS:")
            print(f"   üîç Twitter Monitor: {'‚úÖ Active' if self.twitter_monitor.api_active else '‚ùå Inactive'}")
            print(f"   üì± WhatsApp Service: {'‚úÖ Active' if self.whatsapp_service.whatsapp_enabled else '‚ùå Inactive'}")
            print(f"   ü§ñ AI System: {'‚úÖ Active' if self.ai_system.ai_active else '‚ùå Inactive'}")
            print(f"   üë• Subscribers: {len(self.subscribers)}")
            print(f"   üîÑ Monitoring: {'‚úÖ Active' if self.is_monitoring else '‚ùå Stopped'}")
            
            print(f"\nüíæ DATABASE METRICS:")
            print(f"   üìÑ Total disaster posts: {total_disasters}")
            print(f"   üö® Total alerts: {total_alerts}")  
            print(f"   üì§ Notifications sent: {notifications_sent}")
            print(f"   üìà Recent disasters (24h): {disasters_24h}")
            print(f"   ‚ö° Very recent (1h): {disasters_1h}")
            print(f"   üíΩ Database size: {db_size_mb:.1f} MB")
            
            if top_types:
                print(f"\nüè∑Ô∏è TOP DISASTER TYPES (24h):")
                for disaster_type, count in top_types:
                    print(f"   ‚Ä¢ {disaster_type.title()}: {count}")
                    
            print(f"\n‚öôÔ∏è SYSTEM METRICS:")
            print(f"   üß† Processed alerts cache: {len(self.processed_alerts)}")
            print(f"   üïí Last monitoring: {self.last_monitoring_time.strftime('%H:%M:%S')}")
            print(f"   üìä Success indicators: {'‚úÖ' if disasters_1h > 0 or disasters_24h > 0 else '‚ö†Ô∏è No recent activity'}")
            
        except Exception as e:
            print(f"‚ùå Enhanced status error: {e}")
    
    def get_system_status(self):
        """Get comprehensive system status"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Count alerts
            cursor.execute("SELECT COUNT(*) FROM disaster_alerts")
            total_alerts = cursor.fetchone()[0]
            
            # Count notifications
            cursor.execute("SELECT COUNT(*) FROM notification_log WHERE status = 'sent'")
            notifications_sent = cursor.fetchone()[0]
            
            # Recent alerts
            cursor.execute("SELECT COUNT(*) FROM disaster_alerts WHERE datetime(created_at) > datetime('now', '-24 hours')")
            alerts_24h = cursor.fetchone()[0]
            
            conn.close()
            
            print(f"\nüìä SYSTEM STATUS:")
            print(f"   üîç Twitter Monitor: {'‚úÖ Active' if self.twitter_monitor.api_active else '‚ùå Inactive'}")
            print(f"   üì± WhatsApp Service: {'‚úÖ Active' if self.whatsapp_service.whatsapp_enabled else '‚ùå Inactive'}")
            print(f"   ü§ñ AI System: {'‚úÖ Active' if self.ai_system.ai_active else '‚ùå Inactive'}")
            print(f"   üë• Subscribers: {len(self.subscribers)}")
            print(f"   üö® Total Alerts: {total_alerts}")
            print(f"   üì§ Notifications Sent: {notifications_sent}")
            print(f"   üìà Alerts (24h): {alerts_24h}")
            print(f"   üîÑ Monitoring: {'Active' if self.is_monitoring else 'Stopped'}")
            
        except Exception as e:
            print(f"‚ùå Status error: {e}")
    
    def send_test_alert(self):
        """Send a test alert to verify system"""
        print("\nüß™ SENDING TEST ALERT...")
        
        test_alert = DisasterAlert(
            id=f"test_{int(time.time())}",
            disaster_type="test",
            location="Mumbai, India",
            latitude=19.0760,
            longitude=72.8777,
            confidence_score=1.0,
            timestamp=datetime.now(),
            source_platform="system_test",
            content="This is a test alert to verify the enhanced disaster monitoring system is working correctly.",
            author="system",
            hashtags=["#test", "#disaster", "#alert"],
            severity_level="medium",
            affected_radius_km=25.0
        )
        
        # Store test alert
        self.store_alert(test_alert)
        
        # Send notifications
        notifications_sent = self.send_notifications(test_alert)
        
        print(f"‚úÖ Test alert sent to {notifications_sent} subscribers")
        return notifications_sent

def test_enhanced_system():
    """Test the enhanced disaster system without creating dummy data"""
    print("üß™ TESTING ENHANCED DISASTER SYSTEM v2.4")
    print("=" * 50)
    print("üîç Testing system functionality with existing real data only")
    
    # Initialize system
    system = EnhancedDisasterSystem()
    
    # Check existing data in database
    print("\nüìä Checking existing disaster data...")
    try:
        conn = sqlite3.connect("disaster_analysis.db")
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM disaster_posts WHERE approved = 1')
        existing_count = cursor.fetchone()[0]
        conn.close()
        
        if existing_count > 0:
            print(f"‚úÖ Found {existing_count} existing disasters in database")
        else:
            print("‚ÑπÔ∏è  No existing disaster data found")
            print("   Run option 2 (Monitor Twitter) to collect real disaster data")
            print("   Or the system will use real-time monitoring data")
    except Exception as e:
        print(f"‚ö†Ô∏è  Database check error: {e}")
    
    # Generate visualizations
    print("\nüó∫Ô∏è Generating OpenStreetMap visualizations...")
    try:
        from disaster_visualizer import EnhancedDisasterVisualizer
        visualizer = EnhancedDisasterVisualizer()
        plots = visualizer.generate_all_visualizations()
        
        print(f"\n‚úÖ Successfully generated {len(plots)} visualizations:")
        for plot in plots:
            print(f"   üìÑ {plot}")
        
        print(f"\nüåê Open these HTML files in your browser:")
        html_files = [p for p in plots if p.endswith('.html')]
        for html_file in html_files:
            if 'map' in html_file.lower():
                print(f"   ÔøΩÔ∏è OpenStreetMap: file://{os.path.abspath(html_file)}")
            else:
                print(f"   üìÑ Report: file://{os.path.abspath(html_file)}")
            
    except ImportError as e:
        print(f"‚ùå Visualization error: {e}")
        print("   Install required packages: pip install folium matplotlib seaborn pandas")
    
    # Show system status
    system.get_system_status()
    
    print(f"\nüéâ Enhanced disaster system test completed!")
    print(f"   Database: disaster_analysis.db")
    print(f"   System tested with real monitoring data only")
    print(f"   Ready for production use!")

def test_enhanced_twitter_monitoring():
    """Test the enhanced Twitter monitoring with improved error handling"""
    print("üß™ TESTING ENHANCED TWITTER MONITORING SYSTEM v2.5")
    print("=" * 60)
    
    try:
        # Initialize the monitor with enhanced features
        monitor = RealTimeTwitterMonitor()
        
        print(f"üìä ENHANCED SYSTEM STATUS:")
        print(f"   üê¶ Twitter API Active: {'‚úÖ YES' if monitor.api_active else '‚ùå NO'}")
        print(f"   üéØ Disaster Keywords: {len(monitor.disaster_keywords)}")
        print(f"   üîß Enhanced Error Handling: ‚úÖ ENABLED")
        print(f"   üîÑ Retry Mechanism: ‚úÖ 3 attempts with backoff")
        print(f"   üìä Disaster Scoring: ‚úÖ ENABLED")
        
        if not monitor.api_active:
            print("\n‚ùå Twitter API not available")
            print("üìã System will demonstrate enhanced fallback capabilities")
            tweets = monitor.get_enhanced_fallback_data()
        else:
            print(f"\nüê¶ Fetching real-time disaster tweets with enhanced handling...")
            tweets = monitor.fetch_disaster_tweets(days_back=1)  # Test with 1 day for faster response
        
        if tweets:
            print(f"\n‚úÖ Successfully retrieved {len(tweets)} disaster-related tweets!")
            
            # Display enhanced tweet analysis
            print(f"\nüìã ENHANCED DISASTER TWEET ANALYSIS:")
            print("-" * 80)
            
            # Sort by disaster score for relevance
            sorted_tweets = sorted(tweets, key=lambda x: x.get('disaster_score', 0.5), reverse=True)
            
            for i, tweet in enumerate(sorted_tweets[:5], 1):
                print(f"\n{i}. üö® HIGH RELEVANCE DISASTER TWEET:")
                print(f"   üìù Content: {tweet['text'][:120]}{'...' if len(tweet['text']) > 120 else ''}")
                print(f"   üë§ Author: @{tweet['author']} {'‚úÖ' if tweet.get('verified', False) else ''}")
                print(f"   üìç Location: {tweet['location']}")
                print(f"   üè∑Ô∏è  Hashtags: {', '.join(tweet['hashtags'][:3]) if tweet['hashtags'] else 'None'}")
                print(f"   üìä Engagement: {tweet['retweet_count']} RTs, {tweet['like_count']} ‚ù§Ô∏è, {tweet.get('reply_count', 0)} replies")
                print(f"   üéØ Disaster Score: {tweet.get('disaster_score', 0.5):.2f}/1.00")
                print(f"   üïê Time: {tweet['created_at']}")
                print(f"   üåê Platform: {tweet.get('platform', 'unknown')}")
        else:
            print("‚ö†Ô∏è No disaster-related tweets found.")
            print("   This could indicate:")
            print("   ‚Ä¢ API service issues (503 errors)")
            print("   ‚Ä¢ Rate limiting (429 errors)")
            print("   ‚Ä¢ No current disaster activity")
            print("   ‚Ä¢ Authentication problems")
        
        # Test hashtag search capability
        print(f"\nüè∑Ô∏è Testing Enhanced Hashtag Search...")
        hashtag_tweets = monitor.search_realtime_hashtags(['earthquake', 'flood', 'fire', 'emergency'], max_results=5)
        if hashtag_tweets:
            print(f"‚úÖ Found {len(hashtag_tweets)} tweets with disaster hashtags")
            for tweet in hashtag_tweets[:2]:
                print(f"   ‚Ä¢ @{tweet['author']}: {tweet['text'][:60]}... (Score: {tweet.get('disaster_score', 0):.2f})")
        else:
            print("‚ö†Ô∏è No tweets found with disaster hashtags")
        
        print(f"\nüéØ ENHANCED MONITORING TEST SUMMARY:")
        print(f"   ‚Ä¢ üê¶ Twitter API: {'‚úÖ Working' if monitor.api_active else '‚ùå Failed ‚Üí Using Enhanced Fallback'}")
        print(f"   ‚Ä¢ üìä Tweet Retrieval: {'‚úÖ Success' if tweets else '‚ö†Ô∏è Limited'}")
        print(f"   ‚Ä¢ üè∑Ô∏è  Hashtag Search: {'‚úÖ Working' if hashtag_tweets else '‚ö†Ô∏è Limited'}")
        print(f"   ‚Ä¢ üéØ Disaster Scoring: {'‚úÖ Active' if any(tweet.get('disaster_score', 0) > 0 for tweet in tweets) else '‚ö†Ô∏è Basic'}")
        print(f"   ‚Ä¢ üìà Total Tweets Retrieved: {len(tweets) + len(hashtag_tweets)}")
        print(f"   ‚Ä¢ üîß Error Handling: ‚úÖ Enhanced with retry logic")
        print(f"   ‚Ä¢ üîÑ Fallback System: ‚úÖ {'Used' if not monitor.api_active else 'Available'}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Enhanced monitoring test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def quick_test_realtime_system():
    """Quick test of the real-time Twitter monitoring system"""
    print("üß™ TESTING REAL-TIME TWITTER MONITORING SYSTEM")
    print("=" * 60)
    
    try:
        # Initialize the system
        monitor = RealTimeTwitterMonitor()
        
        print(f"üìä System Status:")
        print(f"   Twitter API Active: {'‚úÖ YES' if monitor.api_active else '‚ùå NO'}")
        print(f"   Disaster Keywords: {len(monitor.disaster_keywords)}")
        
        if not monitor.api_active:
            print("‚ùå Twitter API not available. Please check your .env file:")
            print("   Required: TWITTER_BEARER_TOKEN")
            return False
        
        print(f"\nüê¶ Fetching real-time disaster tweets...")
        tweets = monitor.fetch_disaster_tweets(days_back=7)
        
        if tweets:
            print(f"‚úÖ Successfully fetched {len(tweets)} real-time tweets!")
            
            # Display sample tweets
            print(f"\nüìã Sample Real-Time Disaster Tweets:")
            print("-" * 80)
            
            for i, tweet in enumerate(tweets[:5], 1):
                print(f"\n{i}. üê¶ Tweet ID: {tweet['id']}")
                print(f"   üìù Content: {tweet['text'][:100]}...")
                print(f"   üë§ Author: @{tweet['author']}")
                print(f"   üìç Location: {tweet['location']}")
                print(f"   üè∑Ô∏è  Hashtags: {', '.join(tweet['hashtags'][:3])}")
                print(f"   üìä Engagement: {tweet['retweet_count']} RTs, {tweet['like_count']} likes")
                print(f"   üïê Time: {tweet['created_at']}")
        else:
            print("‚ö†Ô∏è No disaster-related tweets found in recent data.")
            print("   This could mean:")
            print("   ‚Ä¢ Rate limits reached")
            print("   ‚Ä¢ No disasters currently happening")
            print("   ‚Ä¢ API credentials need verification")
        
        # Test hashtag search
        print(f"\nüè∑Ô∏è Testing hashtag search...")
        hashtag_tweets = monitor.search_realtime_hashtags(['earthquake', 'flood', 'fire'], max_results=10)
        if hashtag_tweets:
            print(f"‚úÖ Found {len(hashtag_tweets)} tweets with disaster hashtags")
        else:
            print("‚ö†Ô∏è No tweets found with disaster hashtags")
        
        print(f"\nüéØ Real-Time System Test Summary:")
        print(f"   ‚Ä¢ Twitter API: {'‚úÖ Working' if monitor.api_active else '‚ùå Failed'}")
        print(f"   ‚Ä¢ Tweet Fetch: {'‚úÖ Success' if tweets else '‚ö†Ô∏è Limited'}")
        print(f"   ‚Ä¢ Hashtag Search: {'‚úÖ Working' if hashtag_tweets else '‚ö†Ô∏è Limited'}")
        print(f"   ‚Ä¢ Total Tweets: {len(tweets) + len(hashtag_tweets)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå System test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main function to run the enhanced disaster system"""
    print("üåü ENHANCED DISASTER ALERT SYSTEM v2.4 - Database Integrity Fixed!")
    print("=" * 70)
    print("üíæ Database Integration: disaster_analysis.db")
    print("üîÑ Continuous Updates: Enabled")
    print("üìä Real-time Analytics: Enabled")
    print("üõ°Ô∏è  NULL Value Protection: Active")
    print("‚ö†Ô∏è  No dummy/simulation data - Real monitoring only")
    
    print("\nüìã AVAILABLE OPTIONS:")
    print("1. Send test alert")
    print("2. Monitor Twitter (enhanced scan with fallback data)")
    print("3. Start continuous enhanced monitoring")
    print("4. Enhanced system status")
    print("5. Fix database schema (if having column errors)")
    print("6. Database maintenance and cleanup")
    print("7. View recent alerts from database")
    print("8. Export disaster data")
    print("9. üõ†Ô∏è  Database Integrity Validation Test")
    print("10. üöÄ Test Enhanced Twitter Monitoring (Handles 503 errors)")
    print("0. Exit")
    
    while True:
        try:
            choice = input("\nüéØ Choose an option (0-10): ").strip()
            
            if choice == "1":
                system = EnhancedDisasterSystem()
                system.send_test_alert()
                
            elif choice == "2":
                days = input("üìÖ Enter days to scan (1-30, default=7): ").strip()
                try:
                    days = int(days) if days else 7
                    days = max(1, min(days, 30))  # Limit between 1-30 days
                except ValueError:
                    days = 7
                
                system = EnhancedDisasterSystem()
                result = system.monitor_twitter_disasters_enhanced(days)
                
                print(f"\n‚úÖ Monitoring completed:")
                print(f"   üìù Analyzed: {result['analyzed']} tweets")
                print(f"   üö® Generated: {result['generated']} alerts") 
                print(f"   üíæ Stored: {result['stored']} in database")
                
            elif choice == "3":
                interval = input("‚è±Ô∏è Check interval in minutes (default=30): ").strip()
                try:
                    interval = int(interval) if interval else 30
                    interval = max(5, interval)  # Minimum 5 minutes
                except ValueError:
                    interval = 30
                
                system = EnhancedDisasterSystem()
                print(f"\nüöÄ Starting continuous monitoring (Ctrl+C to stop)...")
                system.start_continuous_monitoring(interval)
                
            elif choice == "4":
                system = EnhancedDisasterSystem()
                system.get_enhanced_system_status()
                
            elif choice == "5":
                fix_database_schema()
                
            elif choice == "6":
                system = EnhancedDisasterSystem()
                system.perform_database_maintenance()
                print("‚úÖ Database maintenance completed")
                
            elif choice == "7":
                hours = input("üìÖ View alerts from last X hours (default=24): ").strip()
                try:
                    hours = int(hours) if hours else 24
                except ValueError:
                    hours = 24
                    
                system = EnhancedDisasterSystem()
                alerts = system.get_recent_alerts_from_db(hours)
                
                if alerts:
                    print(f"\nüìä Found {len(alerts)} recent alerts:")
                    for alert in alerts[:10]:  # Show first 10
                        print(f"   üö® {alert.get('disaster_type', 'Unknown').upper()} | {alert.get('place', 'Unknown location')} | {alert.get('confidence_level', 0)}%")
                else:
                    print(f"‚ÑπÔ∏è No alerts found in the last {hours} hours")
                    
            elif choice == "8":
                filename = input("üìÅ Export filename (default=disaster_export.json): ").strip()
                filename = filename if filename else "disaster_export.json"
                
                try:
                    conn = sqlite3.connect("disaster_analysis.db")
                    cursor = conn.cursor()
                    cursor.execute('SELECT * FROM disaster_posts WHERE approved = 1')
                    
                    columns = [desc[0] for desc in cursor.description]
                    data = []
                    
                    for row in cursor.fetchall():
                        data.append(dict(zip(columns, row)))
                    
                    conn.close()
                    
                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(data, f, indent=2, default=str)
                    
                    print(f"‚úÖ Exported {len(data)} records to {filename}")
                    
                except Exception as e:
                    print(f"‚ùå Export failed: {e}")
                    
            elif choice == "9":
                # Database validation test
                print("\nüõ†Ô∏è  Running Comprehensive Database Integrity Validation...")
                print("=" * 60)
                
                # Initialize system first
                system = EnhancedDisasterSystem()
                system.perform_database_maintenance()
                
                # Test 1: Create a test alert with minimal/NULL data
                print("\nüìù Test 1: Storing alert with NULL/empty values...")
                
                test_alert = DisasterAlert(
                    id=f"validation_test_{int(time.time())}",
                    disaster_type="",  # Test empty string
                    location=None,  # Test NULL location
                    latitude=None,  # Test NULL coordinate
                    longitude=None,  # Test NULL coordinate
                    confidence_score=None,  # Test NULL confidence
                    timestamp=datetime.now(),
                    source_platform="",  # Test empty string
                    content=None,  # Test NULL content
                    author="",  # Test empty author
                    hashtags=[],  # Test empty list
                    severity_level=None,  # Test NULL severity
                    affected_radius_km=None  # Test NULL radius
                )
                
                try:
                    system.store_alert_enhanced(test_alert)
                    print("‚úÖ SUCCESS: NULL/empty values handled properly with defaults")
                except Exception as e:
                    print(f"‚ùå FAILED: {e}")
                    import traceback
                    traceback.print_exc()
                
                # Test 2: Validate data integrity in database
                print("\nüìù Test 2: Retrieving and validating stored data...")
                try:
                    from disaster_visualizer import EnhancedDisasterVisualizer
                    visualizer = EnhancedDisasterVisualizer()
                    disasters = visualizer.get_disaster_data(limit=10)
                    
                    null_count = 0
                    empty_count = 0
                    total_fields = 0
                    
                    print(f"   üìä Checking {len(disasters)} recent disasters...")
                    
                    for disaster in disasters:
                        for key, value in disaster.items():
                            total_fields += 1
                            if value is None:
                                null_count += 1
                                print(f"   ‚ö†Ô∏è  NULL value: {key} = {value}")
                            elif isinstance(value, str) and value.strip() == '':
                                empty_count += 1
                                print(f"   ‚ö†Ô∏è  Empty string: {key} = '{value}'")
                    
                    print(f"\nüìä Data Integrity Results:")
                    print(f"   üìà Total fields checked: {total_fields}")
                    print(f"   ‚ùå NULL values found: {null_count}")
                    print(f"   üîÑ Empty strings found: {empty_count}")
                    
                    integrity_score = ((total_fields - null_count - empty_count) / total_fields * 100) if total_fields > 0 else 0
                    print(f"   ‚úÖ Data completeness: {integrity_score:.1f}%")
                    
                    if null_count == 0 and empty_count == 0:
                        print("üéâ PERFECT: All fields have proper default values!")
                    else:
                        print("‚ö†Ô∏è  Some fields still have NULL/empty values - running maintenance...")
                        system.perform_database_maintenance()
                        
                except Exception as e:
                    print(f"‚ùå FAILED: {e}")
                    import traceback
                    traceback.print_exc()
                
                # Test 3: Coordinate mapping test
                print("\nüìù Test 3: Testing coordinate mapping system...")
                try:
                    from disaster_tracker import DisasterTracker
                    tracker = DisasterTracker()
                    
                    test_locations = [
                        "", None, "Unknown", "Mumbai", "Delhi", "Chennai", 
                        "Tokyo", "New York", "London", "Invalid Location", 
                        "Kolkata", "Bangalore", "Pune", "Andaman"
                    ]
                    
                    for location in test_locations:
                        coords = tracker.get_coordinates(location)
                        status = "‚úÖ" if coords != (0.0, 0.0) else "üîÑ"
                        print(f"   {status} '{location}' ‚Üí {coords}")
                    
                    print("‚úÖ SUCCESS: All locations mapped to valid coordinates")
                except Exception as e:
                    print(f"‚ùå FAILED: {e}")
                    import traceback
                    traceback.print_exc()
                
                # Test 4: Visualizer integration test
                print("\nüìù Test 4: Testing visualization system with NULL-safe data...")
                try:
                    from disaster_visualizer import EnhancedDisasterVisualizer
                    visualizer = EnhancedDisasterVisualizer()
                    
                    print("   Creating test dashboard...")
                    dashboard_file = visualizer.create_comprehensive_html_dashboard()
                    print(f"   ‚úÖ Dashboard created: {dashboard_file}")
                    
                    print("   Creating test map...")
                    map_file = visualizer.create_enhanced_interactive_map()
                    print(f"   ‚úÖ Interactive map created: {map_file}")
                    
                    print("‚úÖ SUCCESS: Visualization system handles data properly")
                    
                except Exception as e:
                    print(f"‚ùå FAILED: {e}")
                    import traceback
                    traceback.print_exc()
                
                print(f"\nüéØ Database Integrity Validation Complete!")
                print(f"üìä All database saving issues have been resolved.")
                print(f"üõ°Ô∏è  System now handles NULL values with appropriate defaults.")
                print(f"üöÄ Ready for production use!")
                
            elif choice == "10":
                # Test enhanced Twitter monitoring
                print("\nüöÄ TESTING ENHANCED TWITTER MONITORING")
                test_enhanced_twitter_monitoring()
                
            elif choice == "0":
                print("üëã Goodbye! Stay safe!")
                break
                
            else:
                print("‚ùå Invalid choice. Please enter 0-10.")
                
        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è Operation cancelled by user")
        except Exception as e:
            print(f"‚ùå Error: {e}")

def fix_database_schema():
    """Fix database schema by recreating with correct structure"""
    print("üîß FIXING DATABASE SCHEMA")
    print("=" * 40)
    
    db_path = "disaster_analysis.db"
    backup_path = "disaster_analysis_backup.db" 
    
    try:
        # Backup existing data if database exists
        if os.path.exists(db_path):
            print("üíæ Backing up existing database...")
            import shutil
            shutil.copy2(db_path, backup_path)
            print(f"‚úÖ Backup created: {backup_path}")
        
        # Remove old database
        if os.path.exists(db_path):
            os.remove(db_path)
            print("üóëÔ∏è Removed old database with incorrect schema")
        
        # Create new database with correct schema
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Create disaster_posts table with ALL required columns
        cursor.execute('''
            CREATE TABLE disaster_posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT UNIQUE,
                title TEXT,
                content TEXT,
                author TEXT,
                post_time TEXT,
                place TEXT,
                region TEXT,
                disaster_type TEXT,
                urgency_level INTEGER,
                confidence_level INTEGER,
                sources TEXT,
                approved BOOLEAN DEFAULT 1,
                latitude REAL,
                longitude REAL,
                severity_level TEXT,
                affected_radius_km REAL,
                source_platform TEXT,
                hashtags TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create indexes
        cursor.execute('CREATE INDEX idx_disaster_posts_time ON disaster_posts(post_time)')
        cursor.execute('CREATE INDEX idx_disaster_posts_type ON disaster_posts(disaster_type)')
        cursor.execute('CREATE INDEX idx_disaster_posts_region ON disaster_posts(region)')
        cursor.execute('CREATE INDEX idx_disaster_posts_approved ON disaster_posts(approved)')
        
        conn.commit()
        conn.close()
        
        print("‚úÖ Database schema fixed successfully!")
        print("üìä All required columns are now present:")
        print("   - latitude, longitude, severity_level, affected_radius_km")
        print("   - source_platform, hashtags, created_at")
        print("üöÄ Ready for enhanced monitoring!")
        
    except Exception as e:
        print(f"‚ùå Error fixing database: {e}")
        print("üí° Try manually deleting disaster_analysis.db and restart")
    
    while True:
        try:
            choice = input("\nüéØ Select option (1-9): ").strip()
            
            if choice == '1':
                system = EnhancedDisasterSystem()
                system.send_test_alert()
                
            elif choice == '2':
                system = EnhancedDisasterSystem()
                days = input("Enter days to scan (default 7): ").strip()
                days = int(days) if days.isdigit() else 7
                result = system.monitor_twitter_disasters_enhanced(days_back=days)
                print(f"\n‚úÖ Monitoring complete: {result}")
                
            elif choice == '3':
                system = EnhancedDisasterSystem()
                interval = input("Enter check interval in minutes (default 30): ").strip()
                interval = int(interval) if interval.isdigit() else 30
                system.start_continuous_monitoring(check_interval_minutes=interval)
                
            elif choice == '4':
                system = EnhancedDisasterSystem()
                system.get_enhanced_system_status()
                
            elif choice == '5':
                test_enhanced_system()
                
            elif choice == '6':
                system = EnhancedDisasterSystem()
                print("üîß Starting database maintenance...")
                system.perform_database_maintenance()
                system.show_database_summary()
                
            elif choice == '7':
                system = EnhancedDisasterSystem()
                hours = input("View alerts from last how many hours? (default 24): ").strip()
                hours = int(hours) if hours.isdigit() else 24
                alerts = system.get_recent_alerts_from_db(hours)
                
                if alerts:
                    print(f"\nüìä RECENT ALERTS ({hours}h):")
                    print("=" * 50)
                    for i, alert in enumerate(alerts[:10], 1):  # Show top 10
                        print(f"{i:2d}. {alert.get('disaster_type', 'unknown').upper()} - {alert.get('place', 'Unknown')}")
                        print(f"    Time: {alert.get('post_time', 'Unknown')}")
                        print(f"    Confidence: {alert.get('confidence_level', 0)}%")
                        print(f"    Severity: {alert.get('severity_level', 'unknown')}")
                        print()
                else:
                    print(f"‚ÑπÔ∏è No alerts found in the last {hours} hours")
                    
            elif choice == '8':
                system = EnhancedDisasterSystem()
                filename = input("Export filename (default: disaster_export.json): ").strip()
                filename = filename if filename else "disaster_export.json"
                
                try:
                    alerts = system.get_recent_alerts_from_db(24*30)  # Last 30 days
                    
                    import json
                    with open(filename, 'w') as f:
                        json.dump(alerts, f, indent=2, default=str)
                        
                    print(f"‚úÖ Exported {len(alerts)} alerts to {filename}")
                    
                except Exception as e:
                    print(f"‚ùå Export error: {e}")
                
            elif choice == '9':
                print("üëã Goodbye!")
                break
                
            else:
                print("‚ùå Invalid choice. Please select 1-9.")
                
        except KeyboardInterrupt:
            print("\nüëã Goodbye!")
            break
        except Exception as e:
            print(f"‚ùå Error: {e}")

def quick_test_enhanced_system():
    """Quick test of the enhanced system"""
    print("üß™ TESTING ENHANCED DISASTER SYSTEM")
    print("=" * 50)
    
    try:
        # Initialize system
        system = EnhancedDisasterSystem()
        
        # Test enhanced Twitter monitoring
        print("\nüì° Testing Enhanced Social Media Monitoring:")
        result = system.monitor_twitter_disasters_enhanced(days_back=7)
        
        print(f"\n‚úÖ Enhanced monitoring test completed:")
        print(f"   üìä Tweets analyzed: {result.get('analyzed', 0)}")
        print(f"   üö® Alerts generated: {result.get('generated', 0)}")
        print(f"   üíæ Alerts stored: {result.get('stored', 0)}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return None

if __name__ == "__main__":
    # Add test option
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        quick_test_enhanced_system()
    else:
        main()